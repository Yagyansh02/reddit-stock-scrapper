{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0cb2abde",
   "metadata": {},
   "source": [
    "# Indian Stock Market Sentiment Analysis from Reddit\n",
    "\n",
    "This notebook makes it very easy for you to create sentiment analysis data from r/indianstocks subreddit about specific Indian stock tickers.\n",
    "\n",
    "## Key Features:\n",
    "- **Stock-Specific Analysis**: Analyzes Hinglish comments for specific Indian stocks (RELIANCE, TCS, HDFC, etc.)\n",
    "- **Dual Sentiment Analysis**: Uses both TextBlob and VADER for comprehensive sentiment scoring\n",
    "- **Real Stock Data**: Pulls live stock market data via Yahoo Finance\n",
    "- **Configurable Parameters**: Easy to change target stock, time period, and analysis depth\n",
    "- **CSV Export**: Automatically produces two CSV files for further analysis\n",
    "\n",
    "## Main Parameters to Customize:\n",
    "- **selectedTickerSymbol**: The NSE stock ticker you want to explore (e.g., 'RELIANCE.NS')\n",
    "- **howmanysubmissions**: Number of submissions to analyze (takes ~5 seconds each)\n",
    "- **time_period**: Analysis period ('week', 'month', 'year')\n",
    "- **min_ticker_mentions**: Minimum mentions required to include a post\n",
    "\n",
    "## Output Files:\n",
    "1. `comment_analysis.csv` - Sentiment analysis results\n",
    "2. `stockticker_history.csv` - Historical stock price data\n",
    "\n",
    "Perfect for analyzing retail investor sentiment on Indian stocks! 📈"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a49b81c9",
   "metadata": {},
   "source": [
    "## 1. Environment Setup and Library Installation\n",
    "\n",
    "First, let's install all the required packages. Uncomment these lines if running for the first time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f995b7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All packages are ready to import!\n"
     ]
    }
   ],
   "source": [
    "# Install required packages (uncomment if running for the first time)\n",
    "# !pip install --upgrade pip\n",
    "# !pip install yfinance --no-dependencies\n",
    "# !pip install multitasking --no-dependencies\n",
    "# !pip install praw\n",
    "# !pip install textblob\n",
    "# !pip install python-dotenv\n",
    "# !pip install nltk\n",
    "\n",
    "# Download NLTK data (uncomment if running for the first time)\n",
    "# import nltk\n",
    "# nltk.download('vader_lexicon')\n",
    "# nltk.download('punkt')\n",
    "\n",
    "print(\"All packages are ready to import!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7687d0df",
   "metadata": {},
   "source": [
    "## 2. Import Required Libraries\n",
    "\n",
    "Import all the necessary libraries for Reddit API access, sentiment analysis, and data processing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d8de7ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " All libraries imported successfully!\n",
      "🇮🇳 Ready for Indian stock market sentiment analysis!\n"
     ]
    }
   ],
   "source": [
    "# Import all required libraries\n",
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "import praw\n",
    "import nltk\n",
    "import os\n",
    "import re\n",
    "from dotenv import load_dotenv\n",
    "from textblob import TextBlob\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Global variables for tracking\n",
    "global selectedTickerSymbolCount\n",
    "global selectedTickerSymbol\n",
    "selectedTickerSymbolCount = 0\n",
    "\n",
    "        print(f\"FINAL COMMENTS SUMMARY:\")\n",
    "print(\"Ready for Indian stock market sentiment analysis!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dca116d",
   "metadata": {},
   "source": [
    "## 3. Load Environment Configuration\n",
    "\n",
    "Load Reddit API credentials from the .env file and set up configuration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b55e826b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reddit API credentials loaded successfully!\n",
      " Client ID: iaho6cAo...\n",
      " User Agent: Common_Attitude_8079\n"
     ]
    }
   ],
   "source": [
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Get Reddit API credentials from environment\n",
    "reddit_client_id = os.getenv('REDDIT_CLIENT_ID')\n",
    "reddit_client_secret = os.getenv('REDDIT_CLIENT_SECRET')\n",
    "reddit_user_agent = os.getenv('REDDIT_USER_AGENT')\n",
    "\n",
    "# Validate credentials\n",
    "if not all([reddit_client_id, reddit_client_secret, reddit_user_agent]):\n",
    "    print(\"Error: Reddit API credentials not found in .env file!\")\n",
    "    print(\"Please ensure your .env file contains:\")\n",
    "    print(\"REDDIT_CLIENT_ID=your_client_id\")\n",
    "    print(\"REDDIT_CLIENT_SECRET=your_client_secret\")\n",
    "    print(\"REDDIT_USER_AGENT=your_user_agent\")\n",
    "else:\n",
    "    print(\"Reddit API credentials loaded successfully!\")\n",
    "    print(f\" Client ID: {reddit_client_id[:8]}...\")\n",
    "    print(f\" User Agent: {reddit_user_agent}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0990ff2c",
   "metadata": {},
   "source": [
    "## 4. Initialize Reddit API Connection\n",
    "\n",
    "Create a Reddit API client using PRAW:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7361e734",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Version 7.7.1 of praw is outdated. Version 7.8.1 was released Friday October 25, 2024.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Successfully connected to Reddit API!\n",
      "🇮🇳 Connected to r/indianstocks - indianstocks\n",
      " Subreddit subscribers: 102,586\n"
     ]
    }
   ],
   "source": [
    "# Create Reddit API client\n",
    "try:\n",
    "    reddit = praw.Reddit(\n",
    "        client_id=reddit_client_id,\n",
    "        client_secret=reddit_client_secret,\n",
    "        user_agent=reddit_user_agent\n",
    "    )\n",
    "    \n",
    "    # Test the connection\n",
    "    test_sub = reddit.subreddit('indianstocks')\n",
    "    print(f\"Successfully connected to Reddit API!\")\n",
    "    print(f\"Connected to r/indianstocks - {test_sub.display_name}\")\n",
    "    print(f\"Subreddit subscribers: {test_sub.subscribers:,}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\" Error connecting to Reddit API: {e}\")\n",
    "    print(\"Please check your credentials in the .env file\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49a2eda1",
   "metadata": {},
   "source": [
    "## 5. Configure Analysis Parameters\n",
    "\n",
    "Set up the main parameters for your analysis. **CUSTOMIZE THESE VALUES**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02027480",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 ANALYSIS CONFIGURATION\n",
      "========================================\n",
      "📈 Target Stock: RELIANCE.NS\n",
      "🇮🇳 Subreddit: r/indianstocks\n",
      "🔢 Submissions to analyze: 100\n",
      "📅 Time period: all (more than 1 year)\n",
      "💬 Analyze comments: True\n",
      "🎯 Min ticker mentions: 1\n",
      "🇮🇳 Hinglish only: True\n",
      "📊 Min Hinglish score: 2\n",
      "========================================\n"
     ]
    }
   ],
   "source": [
    "# ===== MAIN CONFIGURATION PARAMETERS =====\n",
    "# Change these values to customize your analysis\n",
    "\n",
    "# 📈 SELECT YOUR STOCK (NSE symbols - add .NS for Yahoo Finance)\n",
    "selectedTickerSymbol = 'RELIANCE.NS'  # Options: RELIANCE.NS, TCS.NS, HDFCBANK.NS, INFY.NS, etc.\n",
    "\n",
    "# 🇮🇳 TARGET SUBREDDIT (indianstocks is perfect for Indian stocks)\n",
    "selectedsubreddit = 'indianstocks'\n",
    "\n",
    "# 🔢 NUMBER OF SUBMISSIONS TO ANALYZE\n",
    "howmanysubmissions = 100  # Start small (100), can increase to 1000+ for comprehensive analysis\n",
    "\n",
    "# 📅 TIME PERIOD FOR POSTS\n",
    "time_period = 'all'  # Extended to get more than a year of data\n",
    "\n",
    "# 🎯 MINIMUM TICKER MENTIONS (filter out posts with fewer mentions)\n",
    "min_ticker_mentions = 1\n",
    "\n",
    "# 📊 ANALYSIS SETTINGS\n",
    "analyze_comments = True  # Set to False to analyze only post titles\n",
    "max_comments_per_post = 100  # Increased for more Hinglish content\n",
    "hinglish_only = True  # Only process Hinglish content\n",
    "min_hinglish_score = 2  # Minimum Hinglish words required\n",
    "\n",
    "# Indian stock tickers and their common name variations\n",
    "stock_variations = {\n",
    "    'RELIANCE.NS': ['reliance', 'ril', 'mukesh ambani'],\n",
    "    'TCS.NS': ['tcs', 'tata consultancy', 'tata consulting'],\n",
    "    'HDFCBANK.NS': ['hdfc bank', 'hdfc', 'hdfcbank'],\n",
    "    'INFY.NS': ['infosys', 'infy', 'infy'],\n",
    "    'ICICIBANK.NS': ['icici bank', 'icici', 'icicibank'],\n",
    "    'SBIN.NS': ['sbi', 'state bank', 'sbin'],\n",
    "    'BHARTIARTL.NS': ['airtel', 'bharti airtel', 'bharti'],\n",
    "    'ADANIENT.NS': ['adani', 'adani enterprises', 'gautam adani']\n",
    "}\n",
    "\n",
    "print(\"ANALYSIS CONFIGURATION\")\n",
    "print(\"=\" * 40)\n",
    "print(f\"Target Stock: {selectedTickerSymbol}\")\n",
    "print(f\"Subreddit: r/{selectedsubreddit}\")\n",
    "print(f\"Submissions to analyze: {howmanysubmissions}\")\n",
    "print(f\"Time period: {time_period} (more than 1 year)\")\n",
    "print(f\"Analyze comments: {analyze_comments}\")\n",
    "print(f\"Min ticker mentions: {min_ticker_mentions}\")\n",
    "print(f\"Hinglish only: {hinglish_only}\")\n",
    "print(f\"Min Hinglish score: {min_hinglish_score}\")\n",
    "print(\"=\" * 40)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "448a62fa",
   "metadata": {},
   "source": [
    "## 6. Define Sentiment Analysis Functions\n",
    "\n",
    "Create functions for sentiment analysis using both TextBlob and VADER:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa0f37b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📚 Downloading NLTK data...\n",
      "✅ NLTK data downloaded successfully!\n",
      "✅ VADER sentiment analyzer initialized!\n",
      "✅ Sentiment analysis functions defined!\n",
      "🔧 Using TextBlob and VADER for comprehensive sentiment scoring\n",
      "🇮🇳 Enhanced Hinglish detection with scoring system\n",
      "📊 Added combined sentiment labeling (bullish/bearish/neutral)\n"
     ]
    }
   ],
   "source": [
    "# Download required NLTK data first\n",
    "import nltk\n",
    "print(\"Downloading NLTK data...\")\n",
    "try:\n",
    "    nltk.download('vader_lexicon', quiet=True)\n",
    "    nltk.download('punkt', quiet=True)\n",
    "    print(\"NLTK data downloaded successfully!\")\n",
    "except Exception as e:\n",
    "    print(f\"NLTK data download failed: {e}\")\n",
    "\n",
    "# Initialize VADER sentiment analyzer\n",
    "try:\n",
    "    sia = SentimentIntensityAnalyzer()\n",
    "    print(\"VADER sentiment analyzer initialized!\")\n",
    "except Exception as e:\n",
    "    print(f\"Failed to initialize VADER: {e}\")\n",
    "    sia = None\n",
    "\n",
    "def text_blob_sentiment(text, sub_entries_textblob):\n",
    "    \"\"\"\n",
    "    Sentiment analysis using TextBlob\n",
    "    Returns: 'Positive', 'Negative', or 'Neutral'\n",
    "    \"\"\"\n",
    "    try:\n",
    "        analysis = TextBlob(str(text))\n",
    "        polarity = analysis.sentiment.polarity\n",
    "        \n",
    "        if polarity > 0.1:  # More lenient threshold for positive\n",
    "            sub_entries_textblob['positive'] += 1\n",
    "            return 'Positive'\n",
    "        elif polarity < -0.1:  # More lenient threshold for negative\n",
    "            sub_entries_textblob['negative'] += 1\n",
    "            return 'Negative'\n",
    "        else:\n",
    "            sub_entries_textblob['neutral'] += 1\n",
    "            return 'Neutral'\n",
    "    except:\n",
    "        sub_entries_textblob['neutral'] += 1\n",
    "        return 'Neutral'\n",
    "\n",
    "def nltk_sentiment(text, sub_entries_nltk):\n",
    "    \"\"\"\n",
    "    Sentiment analysis using VADER (NLTK)\n",
    "    Returns: 'Positive', 'Negative', or 'Neutral'\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if sia is None:\n",
    "            sub_entries_nltk['neutral'] += 1\n",
    "            return 'Neutral'\n",
    "            \n",
    "        vs = sia.polarity_scores(str(text))\n",
    "        compound_score = vs['compound']\n",
    "        \n",
    "        if compound_score >= 0.05:  # Positive sentiment\n",
    "            sub_entries_nltk['positive'] += 1\n",
    "            return 'Positive'\n",
    "        elif compound_score <= -0.05:  # Negative sentiment\n",
    "            sub_entries_nltk['negative'] += 1\n",
    "            return 'Negative'\n",
    "        else:  # Neutral sentiment\n",
    "            sub_entries_nltk['neutral'] += 1\n",
    "            return 'Neutral'\n",
    "    except:\n",
    "        sub_entries_nltk['neutral'] += 1\n",
    "        return 'Neutral'\n",
    "\n",
    "def is_hinglish(text):\n",
    "    \"\"\"\n",
    "    Enhanced Hinglish detection with scoring system\n",
    "    Returns (is_hinglish_boolean, hinglish_score)\n",
    "    \"\"\"\n",
    "    hinglish_words = [\n",
    "        # Basic Hindi words\n",
    "        'hai', 'hain', 'kar', 'kya', 'aur', 'bhi', 'main', 'yeh', 'woh', 'jo',\n",
    "        'abhi', 'phir', 'bhai', 'yaar', 'achha', 'bura', 'sahi', 'galat',\n",
    "        # Financial Hindi terms\n",
    "        'paisa', 'lakh', 'crore', 'khareed', 'bech', 'munafa', 'nuksan',\n",
    "        'gira', 'gaya', 'jayega', 'badhega', 'giregi', 'upar', 'niche',\n",
    "        # Common Hinglish expressions\n",
    "        'kaise', 'kahan', 'kab', 'kyun', 'koi', 'sabse', 'zyada', 'kam',\n",
    "        'bhot', 'bahut', 'thoda', 'pura', 'sab', 'kuch', 'aise', 'waise',\n",
    "        # Market specific\n",
    "        'stock', 'share', 'market', 'trade', 'buy', 'sell', 'profit', 'loss',\n",
    "        'rupee', 'rs', 'inr', 'portfolio', 'invest', 'investment',\n",
    "        # Sentiment words\n",
    "        'mast', 'zabardast', 'bakwas', 'bekar', 'kamaal', 'shandar'\n",
    "    ]\n",
    "    \n",
    "    if not text:\n",
    "        return False, 0\n",
    "        \n",
    "    text_lower = str(text).lower()\n",
    "    hinglish_score = sum(1 for word in hinglish_words if word in text_lower)\n",
    "    \n",
    "    return hinglish_score >= 2, hinglish_score\n",
    "\n",
    "def get_sentiment_label(textblob_sentiment, vader_sentiment):\n",
    "    \"\"\"\n",
    "    Combine TextBlob and VADER to create final sentiment label\n",
    "    Returns: 'bullish', 'bearish', or 'neutral'\n",
    "    \"\"\"\n",
    "    # Create scoring system\n",
    "    score = 0\n",
    "    \n",
    "    # VADER scoring\n",
    "    if vader_sentiment == 'Positive':\n",
    "        score += 1\n",
    "    elif vader_sentiment == 'Negative':\n",
    "        score -= 1\n",
    "    \n",
    "    # TextBlob scoring  \n",
    "    if textblob_sentiment == 'Positive':\n",
    "        score += 1\n",
    "    elif textblob_sentiment == 'Negative':\n",
    "        score -= 1\n",
    "    \n",
    "    # Final label based on combined score\n",
    "    if score > 0:\n",
    "        return 'bullish'\n",
    "    elif score < 0:\n",
    "        return 'bearish'\n",
    "    else:\n",
    "        return 'neutral'\n",
    "\n",
    "print(\"Sentiment analysis functions defined!\")\n",
    "print(\"Using TextBlob and VADER for comprehensive sentiment scoring\")\n",
    "print(\"Enhanced Hinglish detection with scoring system\")\n",
    "print(\"Added combined sentiment labeling (bullish/bearish/neutral)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a646812f",
   "metadata": {},
   "source": [
    "## 7. Implement Comment Processing Functions\n",
    "\n",
    "Functions to recursively process Reddit comments and count ticker mentions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5d00402",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Comment processing functions defined!\n",
      "🔄 Ready to recursively analyze Reddit comment threads\n",
      "📊 Ticker mention counting with variations included\n"
     ]
    }
   ],
   "source": [
    "def count_ticker_mentions(text, ticker_symbol):\n",
    "    \"\"\"\n",
    "    Count mentions of the ticker symbol and its variations in text\n",
    "    \"\"\"\n",
    "    global selectedTickerSymbolCount\n",
    "    \n",
    "    if not text:\n",
    "        return 0\n",
    "    \n",
    "    text_lower = str(text).lower()\n",
    "    count = 0\n",
    "    \n",
    "    # Get the base ticker (remove .NS suffix for searching)\n",
    "    base_ticker = ticker_symbol.replace('.NS', '').lower()\n",
    "    \n",
    "    # Count direct ticker mentions\n",
    "    count += text_lower.count(base_ticker)\n",
    "    \n",
    "    # Count variations if they exist in our mapping\n",
    "    if ticker_symbol in stock_variations:\n",
    "        for variation in stock_variations[ticker_symbol]:\n",
    "            count += text_lower.count(variation.lower())\n",
    "    \n",
    "    selectedTickerSymbolCount += count\n",
    "    return count\n",
    "\n",
    "def process_comment_replies(top_level_comment, sub_entries_textblob, sub_entries_nltk, ticker_symbol):\n",
    "    \"\"\"\n",
    "    Recursively process comment replies\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if hasattr(top_level_comment, 'replies') and len(top_level_comment.replies) > 0:\n",
    "            for comment in top_level_comment.replies:\n",
    "                try:\n",
    "                    if hasattr(comment, 'body') and comment.body not in ['[deleted]', '[removed]']:\n",
    "                        # Analyze sentiment\n",
    "                        text_blob_sentiment(comment.body, sub_entries_textblob)\n",
    "                        nltk_sentiment(comment.body, sub_entries_nltk)\n",
    "                        \n",
    "                        # Count ticker mentions\n",
    "                        count_ticker_mentions(comment.body, ticker_symbol)\n",
    "                        \n",
    "                        # Process nested replies\n",
    "                        process_comment_replies(comment, sub_entries_textblob, sub_entries_nltk, ticker_symbol)\n",
    "                        \n",
    "                except Exception as e:\n",
    "                    continue\n",
    "    except Exception as e:\n",
    "        pass\n",
    "\n",
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "    Clean text for better analysis\n",
    "    \"\"\"\n",
    "    if not text:\n",
    "        return \"\"\n",
    "    \n",
    "    # Remove URLs\n",
    "    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', str(text), flags=re.MULTILINE)\n",
    "    \n",
    "    # Remove excessive whitespace\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    \n",
    "    return text\n",
    "\n",
    "print(\"Comment processing functions defined!\")\n",
    "print(\"Ready to recursively analyze Reddit comment threads\")\n",
    "print(\"Ticker mention counting with variations included\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10071cf5",
   "metadata": {},
   "source": [
    "## 8. Fetch Stock Market Data\n",
    "\n",
    "Use Yahoo Finance to get historical stock data for the selected ticker:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ad6aad8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Fetching stock data for RELIANCE.NS...\n",
      "Stock data fetched successfully!\n",
      "==================================================\n",
      " Company: Reliance Industries Limited\n",
      " Sector: Energy\n",
      "🇮🇳 Exchange: NSI\n",
      " Market Cap: ₹18,450,172,870,656\n",
      "==================================================\n",
      " Latest Price: ₹1363.40\n",
      " Price Change: ₹-5.30 (-0.39%)\n",
      " Data Range: 2024-10-03 to 2025-10-03\n",
      " Total Records: 252\n"
     ]
    }
   ],
   "source": [
    "# Fetch stock market data using Yahoo Finance\n",
    "print(f\"Fetching stock data for {selectedTickerSymbol}...\")\n",
    "\n",
    "try:\n",
    "    # Create ticker object\n",
    "    selected_ticker = yf.Ticker(selectedTickerSymbol)\n",
    "    \n",
    "    # Get historical data (last 1 year for context)\n",
    "    stock_history = selected_ticker.history(period=\"1y\")\n",
    "    \n",
    "    # Get basic info\n",
    "    stock_info = selected_ticker.info\n",
    "    \n",
    "    print(\"Stock data fetched successfully!\")\n",
    "    print(\"=\" * 50)\n",
    "    print(f\"Company: {stock_info.get('longName', 'N/A')}\")\n",
    "    print(f\"Sector: {stock_info.get('sector', 'N/A')}\")\n",
    "    print(f\"Exchange: {stock_info.get('exchange', 'N/A')}\")\n",
    "    print(f\"Market Cap: Rs{stock_info.get('marketCap', 0):,}\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Display recent price data\n",
    "    if not stock_history.empty:\n",
    "        latest_price = stock_history['Close'].iloc[-1]\n",
    "        price_change = stock_history['Close'].iloc[-1] - stock_history['Close'].iloc[-2]\n",
    "        price_change_pct = (price_change / stock_history['Close'].iloc[-2]) * 100\n",
    "        \n",
    "        print(f\"Latest Price: Rs{latest_price:.2f}\")\n",
    "        print(f\"Price Change: Rs{price_change:.2f} ({price_change_pct:+.2f}%)\")\n",
    "        print(f\"Data Range: {stock_history.index[0].date()} to {stock_history.index[-1].date()}\")\n",
    "        print(f\"Total Records: {len(stock_history)}\")\n",
    "    else:\n",
    "        print(\" No stock price data available\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\" Error fetching stock data: {e}\")\n",
    "    stock_history = pd.DataFrame()\n",
    "    stock_info = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7d40a08",
   "metadata": {},
   "source": [
    "## 9. Process Reddit Submissions\n",
    "\n",
    "Main analysis loop - process Reddit posts and comments:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6200f82",
   "metadata": {},
   "source": [
    "## 9. Extract Individual Comments\n",
    "\n",
    "Extract and analyze individual comments from posts instead of just post titles:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c4f04062",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Starting comment extraction from r/indianstocks for RELIANCE.NS\n",
      "🔍 Extracting individual Hinglish comments with sentiment labels\n",
      "============================================================\n",
      " Processing 100 posts to extract individual comments...\n",
      " This may take several minutes...\n",
      "\n",
      "Post 1: This is what real ball looks like.....\n",
      "   💬 Extracted 0 relevant comments\n",
      "\n",
      "Post 2: Telegram Trader's...\n",
      "   💬 Extracted 0 relevant comments\n",
      "\n",
      "Post 3: Never forget...\n",
      "   💬 Extracted 0 relevant comments\n",
      "\n",
      "Post 4: I didn’t touch my stocks for 4 years and this is the result…...\n",
      "   💬 Extracted 0 relevant comments\n",
      "\n",
      "Post 5: OMG Now What 😱...\n",
      "   💬 Extracted 1 relevant comments\n",
      "\n",
      "Post 6: Indians are getting out of poverty 🇮🇳👍...\n",
      "   💬 Extracted 0 relevant comments\n",
      "\n",
      "Post 7: Indian market these days....\n",
      "   💬 Extracted 0 relevant comments\n",
      "\n",
      "Post 8: How do tariffs work?...\n",
      "   💬 Extracted 0 relevant comments\n",
      "\n",
      "Post 9: Rate My Portfolio 😁😁...\n",
      "   💬 Extracted 1 relevant comments\n",
      "\n",
      "Post 10: Made my first ₹100 profit!...\n",
      "   💬 Extracted 0 relevant comments\n",
      "\n",
      "Post 11: Holding since IPO...\n",
      "   💬 Extracted 0 relevant comments\n",
      "\n",
      "Post 12: All these companies rake in 40-80% of their revenue from the...\n",
      "   💬 Extracted 0 relevant comments\n",
      "\n",
      "Post 13: Capital Gains Tax: India vs few other countries...\n",
      "   💬 Extracted 0 relevant comments\n",
      "\n",
      "Post 14: Should I sell??...\n",
      "   💬 Extracted 0 relevant comments\n",
      "\n",
      "Post 15: Made some investments in 2016-2018 period and did not touch ...\n",
      "   💬 Extracted 0 relevant comments\n",
      "\n",
      "Post 16: Indian Companies Exposure to USA & their Sales contribution...\n",
      "   💬 Extracted 0 relevant comments\n",
      "\n",
      "Post 17: NETWEB made me 150% in 4 months....\n",
      "   💬 Extracted 0 relevant comments\n",
      "\n",
      "Post 18: Thanks to random anonymous reddit user...\n",
      "   💬 Extracted 0 relevant comments\n",
      "\n",
      "Post 19: Crossed 1 Crore today...\n",
      "   💬 Extracted 0 relevant comments\n",
      "\n",
      "Post 20: How it will going to impact oil stocks?...\n",
      "   💬 Extracted 2 relevant comments\n",
      "\n",
      "Post 21: Do you think the market will fall because of the recent \"for...\n",
      "   💬 Extracted 1 relevant comments\n",
      "\n",
      "Post 22: Sell time? Big win...\n",
      "   💬 Extracted 0 relevant comments\n",
      "\n",
      "Post 23: At the end of the year, I got a 46% return this year. How mu...\n",
      "   💬 Extracted 1 relevant comments\n",
      "\n",
      "Post 24: India Tops Hong Kong as World’s Fourth-Largest Stock Market...\n",
      "   💬 Extracted 0 relevant comments\n",
      "\n",
      "Post 25: You can get Generational Wealth in Market...Just Don't Quit ...\n",
      "   💬 Extracted 0 relevant comments\n",
      "\n",
      "Post 26: Found Something Unexpected While Cleaning for Diwali...\n",
      "   💬 Extracted 0 relevant comments\n",
      "\n",
      "Post 27: Zerodha's market share is shrinking?...\n",
      "   💬 Extracted 0 relevant comments\n",
      "\n",
      "Post 28: I regret not buying more ITC at those levels ☹️...\n",
      "   💬 Extracted 0 relevant comments\n",
      "\n",
      "Post 29: Zerodha CEO gives a detailed reply to a Reddit question on p...\n",
      "   💬 Extracted 0 relevant comments\n",
      "\n",
      "Post 30: Trump after tariff...\n",
      "   💬 Extracted 0 relevant comments\n",
      "\n",
      "Post 31: At 23 made first lakh with investing any suggestions?...\n",
      "   💬 Extracted 0 relevant comments\n",
      "\n",
      "Post 32: My Portfolio hit 50K...\n",
      "   💬 Extracted 0 relevant comments\n",
      "\n",
      "Post 33: China's Embassy in the US posted this on Donald Trump's tarr...\n",
      "   💬 Extracted 0 relevant comments\n",
      "\n",
      "Post 34: My First ever trade...\n",
      "   💬 Extracted 0 relevant comments\n",
      "\n",
      "Post 35: This is how a 4 year old portfolio should look like. XIRR is...\n",
      "   💬 Extracted 0 relevant comments\n",
      "\n",
      "Post 36: what happened?...\n",
      "   💬 Extracted 0 relevant comments\n",
      "\n",
      "Post 37: How fucked am i...\n",
      "   💬 Extracted 0 relevant comments\n",
      "\n",
      "Post 38: Why this meme is soo close to my reality...\n",
      "   💬 Extracted 0 relevant comments\n",
      "\n",
      "Post 39: Rate my investment.......\n",
      "   💬 Extracted 0 relevant comments\n",
      "\n",
      "Post 40: Guys,tell me a right price to buy this...\n",
      "   💬 Extracted 0 relevant comments\n",
      "\n",
      "Post 41: I lost everything.......\n",
      "   💬 Extracted 1 relevant comments\n",
      "\n",
      "Post 42: Patience is the key...\n",
      "   💬 Extracted 0 relevant comments\n",
      "\n",
      "Post 43: Why are gold prices rising?...\n",
      "   💬 Extracted 0 relevant comments\n",
      "\n",
      "Post 44: Looking to hold for next 3 years...\n",
      "   💬 Extracted 0 relevant comments\n",
      "\n",
      "Post 45: I am scared, What should I do?...\n",
      "   💬 Extracted 1 relevant comments\n",
      "\n",
      "Post 46: No returns in 3 years 😌...\n",
      "   💬 Extracted 0 relevant comments\n",
      "\n",
      "Post 47: Regret not adding more!...\n",
      "   💬 Extracted 0 relevant comments\n",
      "\n",
      "Post 48: NETWEB doubled in 9 weeks for me. What to do?...\n",
      "   💬 Extracted 0 relevant comments\n",
      "\n",
      "Post 49: Bought this today...thoughts?...\n",
      "   💬 Extracted 0 relevant comments\n",
      "\n",
      "Post 50: As a 27yo, am I investing correctly?...\n",
      "   💬 Extracted 0 relevant comments\n",
      "\n",
      "Post 51: Gold my beloved. It's given me better returns in 4 months th...\n",
      "   💬 Extracted 0 relevant comments\n",
      "\n",
      "Post 52: Nifty call or put?...\n",
      "   💬 Extracted 2 relevant comments\n",
      "\n",
      "Post 53: My first trade...\n",
      "   💬 Extracted 0 relevant comments\n",
      "\n",
      "Post 54: Here's my portfolio: Investing for the long term. Your view ...\n",
      "   💬 Extracted 1 relevant comments\n",
      "\n",
      "Post 55: What's your opinion...\n",
      "   💬 Extracted 0 relevant comments\n",
      "\n",
      "Post 56: What say guys? Double down?...\n",
      "   💬 Extracted 0 relevant comments\n",
      "\n",
      "Post 57: What does this mean...\n",
      "   💬 Extracted 1 relevant comments\n",
      "\n",
      "Post 58: Please review my portfolio...\n",
      "   💬 Extracted 0 relevant comments\n",
      "\n",
      "Post 59: Is this normal...\n",
      "   💬 Extracted 0 relevant comments\n",
      "\n",
      "Post 60: Rate My Portfolio and Advice ?...\n",
      "   💬 Extracted 0 relevant comments\n",
      "\n",
      "Post 61: Hyundai plans a $3 billion IPO for its India operation, valu...\n",
      "   💬 Extracted 0 relevant comments\n",
      "\n",
      "Post 62: Best decicion to not square off WAREEENER...thanks to Dad...\n",
      "   💬 Extracted 0 relevant comments\n",
      "\n",
      "Post 63: Made 54% returns in 5 years of investing bit by bit. Anythin...\n",
      "   💬 Extracted 0 relevant comments\n",
      "\n",
      "Post 64: Made good money....\n",
      "   💬 Extracted 0 relevant comments\n",
      "\n",
      "Post 65: Catch it Before it Explodes !!...\n",
      "   💬 Extracted 0 relevant comments\n",
      "\n",
      "Post 66: After good response/comments for my ICICI demat account, ple...\n",
      "   💬 Extracted 0 relevant comments\n",
      "\n",
      "Post 67: Went all in on Gold & Silver...\n",
      "   💬 Extracted 0 relevant comments\n",
      "\n",
      "Post 68: Stay or Leave?...\n",
      "   💬 Extracted 1 relevant comments\n",
      "\n",
      "Post 69: Trump has played the game well...\n",
      "   💬 Extracted 1 relevant comments\n",
      "\n",
      "Post 70: Some shares I am planning to buy tomorrow... Any suggestions...\n",
      "   💬 Extracted 0 relevant comments\n",
      "\n",
      "Post 71: Bye Bye FnO account...\n",
      "   💬 Extracted 0 relevant comments\n",
      "\n",
      "Post 72: Indians Pay More for Petrol Than Americans, Chinese & Pakist...\n",
      "   💬 Extracted 0 relevant comments\n",
      "\n",
      "Post 73: Good time to buy?...\n",
      "   💬 Extracted 0 relevant comments\n",
      "\n",
      "Post 74: Rate my portfolio out of 10...\n",
      "   💬 Extracted 0 relevant comments\n",
      "\n",
      "Post 75: Should I hold it or sell it?...\n",
      "   💬 Extracted 0 relevant comments\n",
      "\n",
      "Post 76: India has been the worst performing market in the world over...\n",
      "   💬 Extracted 0 relevant comments\n",
      "\n",
      "Post 77: Rate my portfolio...\n",
      "   💬 Extracted 0 relevant comments\n",
      "\n",
      "Post 78: My plan for 2 lakh investment...\n",
      "   💬 Extracted 0 relevant comments\n",
      "\n",
      "Post 79: What should I do with Tata Technologies ?...\n",
      "   💬 Extracted 0 relevant comments\n",
      "\n",
      "Post 80: Small Stock price Vs Small Company...\n",
      "   💬 Extracted 0 relevant comments\n",
      "\n",
      "Post 81: US markets are crazyyy...\n",
      "   💬 Extracted 1 relevant comments\n",
      "\n",
      "Post 82: By mistake clicked 5 instead of 50...\n",
      "   💬 Extracted 0 relevant comments\n",
      "\n",
      "Post 83: Made ₹2460 profit this month from delivery stocks, paying ₹3...\n",
      "   💬 Extracted 0 relevant comments\n",
      "\n",
      "Post 84: Buy now or wait ? Tell me experts...\n",
      "   💬 Extracted 0 relevant comments\n",
      "\n",
      "Post 85: Wait for 1 Cr. Or Exit ?...\n",
      "   💬 Extracted 0 relevant comments\n",
      "\n",
      "Post 86: Rate this portfolio...\n",
      "   💬 Extracted 1 relevant comments\n",
      "\n",
      "Post 87: My portfolio at 22....\n",
      "   💬 Extracted 0 relevant comments\n",
      "\n",
      "Post 88: Hyundai is here 🔥🔥...\n",
      "   💬 Extracted 0 relevant comments\n",
      "\n",
      "Post 89: TCS: A buying opportunity? Please suggest....\n",
      "   💬 Extracted 0 relevant comments\n",
      "\n",
      "Post 90: Found my dad’s stock portfolio — where do I start?...\n",
      "   💬 Extracted 0 relevant comments\n",
      "\n",
      "Post 91: Help with your suggestion and rate my portfolio as newbie....\n",
      "   💬 Extracted 0 relevant comments\n",
      "\n",
      "Post 92: What should I do and don't...\n",
      "   💬 Extracted 0 relevant comments\n",
      "\n",
      "Post 93: Damn. Got a Valentine gift...\n",
      "   💬 Extracted 0 relevant comments\n",
      "\n",
      "Post 94: Should I buy it? Is it right time...\n",
      "   💬 Extracted 0 relevant comments\n",
      "\n",
      "Post 95: Should I sell or hold?...\n",
      "   💬 Extracted 0 relevant comments\n",
      "\n",
      "Post 96: Want to invest 3 lakhs in stocks. Need help!...\n",
      "   💬 Extracted 0 relevant comments\n",
      "\n",
      "Post 97: Did something positive happen?...\n",
      "   💬 Extracted 0 relevant comments\n",
      "\n",
      "Post 98: Months of research...\n",
      "   💬 Extracted 0 relevant comments\n",
      "\n",
      "Post 99: 30 M , can you guys rate my portfolio and how much can i imp...\n",
      "   💬 Extracted 0 relevant comments\n",
      "\n",
      "Post 100: NIFTY 🫣...\n",
      "   💬 Extracted 0 relevant comments\n",
      "\n",
      " Comment extraction completed!\n",
      "============================================================\n",
      " COMMENT EXTRACTION SUMMARY:\n",
      "    Total posts processed: 100\n",
      "    Total comments extracted: 16\n",
      "   🇮🇳 Hinglish comments found: 16\n",
      "    Final comments dataset size: 16 records\n",
      "\n",
      "📊 COMMENT SENTIMENT BREAKDOWN:\n",
      "    Bullish: 11 (68.8%)\n",
      "    Bearish: 3 (18.8%)\n",
      "    Neutral: 2 (12.5%)\n",
      "\n",
      "🇮🇳 Hinglish Content: 100.0% of extracted comments\n"
     ]
    }
   ],
   "source": [
    "# Extract individual comments from Reddit posts for detailed sentiment analysis\n",
    "print(f\"Starting comment extraction from r/{selectedsubreddit} for {selectedTickerSymbol}\")\n",
    "print(\"Extracting individual Hinglish comments with sentiment labels\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Get Reddit submissions based on time period  \n",
    "try:\n",
    "    if time_period == 'week':\n",
    "        submissions = reddit.subreddit(selectedsubreddit).top('week', limit=howmanysubmissions)\n",
    "    elif time_period == 'month':\n",
    "        submissions = reddit.subreddit(selectedsubreddit).top('month', limit=howmanysubmissions)\n",
    "    elif time_period == 'year':\n",
    "        submissions = reddit.subreddit(selectedsubreddit).top('year', limit=howmanysubmissions)\n",
    "    else:\n",
    "        submissions = reddit.subreddit(selectedsubreddit).top('all', limit=howmanysubmissions)\n",
    "    \n",
    "    # Initialize comments dataframe\n",
    "    comments_df = pd.DataFrame()\n",
    "    \n",
    "    # Analysis counters\n",
    "    submission_counter = 1\n",
    "    total_comments_extracted = 0\n",
    "    hinglish_comments_found = 0\n",
    "    \n",
    "    print(f\"Processing {howmanysubmissions} posts to extract individual comments...\")\n",
    "    print(\" This may take several minutes...\\n\")\n",
    "    \n",
    "    # Process each submission\n",
    "    for submission in submissions:\n",
    "        try:\n",
    "            # Clean title and get basic info\n",
    "            clean_title = clean_text(submission.title)\n",
    "            post_date = datetime.fromtimestamp(submission.created_utc)\n",
    "            \n",
    "            print(f\"Post {submission_counter}: {clean_title[:60]}...\")\n",
    "            submission_counter += 1\n",
    "            \n",
    "            # Check if post title mentions our ticker\n",
    "            post_ticker_mentions = 0\n",
    "            selectedTickerSymbolCount = 0\n",
    "            post_ticker_mentions = count_ticker_mentions(clean_title, selectedTickerSymbol)\n",
    "            \n",
    "            # Process comments from this post\n",
    "            try:\n",
    "                submission.comments.replace_more(limit=0)\n",
    "                post_comments_processed = 0\n",
    "                \n",
    "                for comment in submission.comments[:max_comments_per_post]:\n",
    "                    try:\n",
    "                        if hasattr(comment, 'body') and comment.body not in ['[deleted]', '[removed]']:\n",
    "                            clean_comment = clean_text(comment.body)\n",
    "                            \n",
    "                            # Skip very short comments\n",
    "                            if len(clean_comment.split()) < 3:\n",
    "                                continue\n",
    "                            \n",
    "                            # Check for Hinglish in this comment\n",
    "                            is_hinglish_comment, hinglish_score = is_hinglish(clean_comment)\n",
    "                            \n",
    "                            # Check for ticker mentions in comment\n",
    "                            selectedTickerSymbolCount = 0\n",
    "                            comment_ticker_mentions = count_ticker_mentions(clean_comment, selectedTickerSymbol)\n",
    "                            \n",
    "                            # Only process if comment is Hinglish OR mentions ticker (based on your filter settings)\n",
    "                            should_include = True\n",
    "                            if hinglish_only:\n",
    "                                should_include = is_hinglish_comment\n",
    "                            \n",
    "                            if should_include and (comment_ticker_mentions > 0 or post_ticker_mentions > 0):\n",
    "                                # Analyze sentiment for this comment\n",
    "                                comment_textblob = {'negative': 0, 'positive': 0, 'neutral': 0}\n",
    "                                comment_nltk = {'negative': 0, 'positive': 0, 'neutral': 0}\n",
    "                                \n",
    "                                tb_sentiment = text_blob_sentiment(clean_comment, comment_textblob)\n",
    "                                vader_sentiment = nltk_sentiment(clean_comment, comment_nltk)\n",
    "                                combined_sentiment = get_sentiment_label(tb_sentiment, vader_sentiment)\n",
    "                                \n",
    "                                # Create comment record\n",
    "                                comment_record = {\n",
    "                                    'Post_Title': clean_title,\n",
    "                                    'Post_ID': submission.id,\n",
    "                                    'Post_Date': post_date.strftime('%Y-%m-%d'),\n",
    "                                    'Post_Score': submission.score,\n",
    "                                    'Comment_Text': clean_comment,\n",
    "                                    'Comment_ID': comment.id,\n",
    "                                    'Comment_Author': str(comment.author) if comment.author else '[deleted]',\n",
    "                                    'Comment_Score': comment.score,\n",
    "                                    'Comment_Date': datetime.fromtimestamp(comment.created_utc).strftime('%Y-%m-%d'),\n",
    "                                    'Ticker': selectedTickerSymbol,\n",
    "                                    'Ticker_Mentions_In_Comment': comment_ticker_mentions,\n",
    "                                    'Ticker_Mentions_In_Post': post_ticker_mentions,\n",
    "                                    'Is_Hinglish': is_hinglish_comment,\n",
    "                                    'Hinglish_Score': hinglish_score,\n",
    "                                    'VADER_Sentiment': vader_sentiment,\n",
    "                                    'TextBlob_Sentiment': tb_sentiment,\n",
    "                                    'Combined_Sentiment': combined_sentiment,\n",
    "                                    'VADER_Compound': comment_nltk.get('positive', 0) - comment_nltk.get('negative', 0),\n",
    "                                    'TextBlob_Polarity': comment_textblob.get('positive', 0) - comment_textblob.get('negative', 0)\n",
    "                                }\n",
    "                                \n",
    "                                # Append to comments dataframe\n",
    "                                comments_df = pd.concat([comments_df, pd.DataFrame([comment_record])], ignore_index=True)\n",
    "                                \n",
    "                                total_comments_extracted += 1\n",
    "                                if is_hinglish_comment:\n",
    "                                    hinglish_comments_found += 1\n",
    "                                \n",
    "                                post_comments_processed += 1\n",
    "                                \n",
    "                    except Exception as e:\n",
    "                        continue\n",
    "                \n",
    "                print(f\"   Extracted {post_comments_processed} relevant comments\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"   ⚠️ Error processing comments: {e}\")\n",
    "            \n",
    "            print()  # Empty line for readability\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"    Error processing submission: {e}\")\n",
    "            continue\n",
    "    \n",
    "    print(\"Comment extraction completed!\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"COMMENT EXTRACTION SUMMARY:\")\n",
    "    print(f\"    Total posts processed: {submission_counter - 1}\")\n",
    "    print(f\"    Total comments extracted: {total_comments_extracted}\")\n",
    "    print(f\"   Hinglish comments found: {hinglish_comments_found}\")\n",
    "    print(f\"    Final comments dataset size: {len(comments_df)} records\")\n",
    "    \n",
    "    # Show sentiment breakdown if we have data\n",
    "    if not comments_df.empty:\n",
    "        sentiment_counts = comments_df['Combined_Sentiment'].value_counts()\n",
    "        print(f\"\\n📊 COMMENT SENTIMENT BREAKDOWN:\")\n",
    "        for sentiment, count in sentiment_counts.items():\n",
    "            print(f\"    {sentiment.title()}: {count} ({count/len(comments_df)*100:.1f}%)\")\n",
    "        \n",
    "        hinglish_percentage = (comments_df['Is_Hinglish'].sum() / len(comments_df)) * 100\n",
    "        print(f\"\\n🇮🇳 Hinglish Content: {hinglish_percentage:.1f}% of extracted comments\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\" Error during comment extraction: {e}\")\n",
    "    comments_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f314bd7",
   "metadata": {},
   "source": [
    "## 10. Display and Export Comments Data\n",
    "\n",
    "Show sample comments and export the individual comments dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "39ce1ffc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " INDIVIDUAL COMMENTS ANALYSIS RESULTS\n",
      "============================================================\n",
      "📝 SAMPLE COMMENTS BY SENTIMENT:\n",
      "----------------------------------------\n",
      "\n",
      "BULLISH Comments (11 total):\n",
      "  📄 \"He has sold his losers and only kept one loser. Thats why the portfolio looks brilliant. He has only...\"\n",
      "     📅 2024-11-07 | 👍 1 | 🇮🇳 Hinglish: True\n",
      "  📄 \"I too searched for this in chat gpt the day this news was published. Here is a narrative of the same...\"\n",
      "     📅 2025-06-16 | 👍 1 | 🇮🇳 Hinglish: True\n",
      "\n",
      "BEARISH Comments (3 total):\n",
      "  📄 \"Bhai meine toh reliance power lia tha 67 pe. Fraud kar dia usne firse aur upar se ye🙂...\"\n",
      "     📅 2025-08-07 | 👍 1 | 🇮🇳 Hinglish: True\n",
      "  📄 \"I know how this feels, most of us have lost money in FnO...be angry at yourself, process every emoti...\"\n",
      "     📅 2025-09-17 | 👍 1 | 🇮🇳 Hinglish: True\n",
      "\n",
      "NEUTRAL Comments (2 total):\n",
      "  📄 \"I can see an Adami Refineries business. I also see 2 trillionaires from India! Investors make more a...\"\n",
      "     📅 2025-06-17 | 👍 1 | 🇮🇳 Hinglish: True\n",
      "  📄 \"Bhai bought reliance at 223, bhai was born when stock market was started...\"\n",
      "     📅 2024-11-07 | 👍 1 | 🇮🇳 Hinglish: True\n",
      "\n",
      "🇮🇳 TOP HINGLISH COMMENTS (Showing 3 examples):\n",
      "----------------------------------------\n",
      "💬 \"The power this man beholds is beyond comprehension. Made countries sweat out of ...\"\n",
      "   Sentiment: bearish | Score: 8 | Date: 2025-04-10\n",
      "\n",
      "💬 \"I too searched for this in chat gpt the day this news was published. Here is a n...\"\n",
      "   Sentiment: bullish | Score: 7 | Date: 2025-06-16\n",
      "\n",
      "💬 \"Bhai meine toh reliance power lia tha 67 pe. Fraud kar dia usne firse aur upar s...\"\n",
      "   Sentiment: bearish | Score: 6 | Date: 2025-08-07\n",
      "\n",
      " COMMENTS DATASET PREVIEW:\n",
      "============================================================\n",
      "                                         Comment_Text Combined_Sentiment  Is_Hinglish  Hinglish_Score Comment_Date\n",
      "Bhai meine toh reliance power lia tha 67 pe. Fraud...            bearish         True               6   2025-08-07\n",
      "He has sold his losers and only kept one loser. Th...            bullish         True               5   2024-11-07\n",
      "I too searched for this in chat gpt the day this n...            bullish         True               7   2025-06-16\n",
      "\n",
      "💾 EXPORTING COMMENTS DATA:\n",
      "==============================\n",
      "✅ Comments data saved: RELIANCE_individual_comments_20251005_190337.csv\n",
      "   📊 Total comments: 16\n",
      "   📋 Columns: 19\n",
      "✅ Hinglish-only data saved: RELIANCE_hinglish_comments_only_20251005_190337.csv\n",
      "   🇮🇳 Hinglish comments: 16\n",
      "\n",
      "🎯 FINAL COMMENTS SUMMARY:\n",
      "   📝 Individual comments extracted: 16\n",
      "   🇮🇳 Pure Hinglish comments: 16\n",
      "   📅 Date range: 2024-01-01 to 2025-09-17\n",
      "   📊 Sentiment distribution:\n",
      "      Bullish: 11 (68.8%)\n",
      "      Bearish: 3 (18.8%)\n",
      "      Neutral: 2 (12.5%)\n"
     ]
    }
   ],
   "source": [
    "# Display and export the extracted comments\n",
    "if not comments_df.empty:\n",
    "    print(\"INDIVIDUAL COMMENTS ANALYSIS RESULTS\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Show sample comments by sentiment\n",
    "    print(\"SAMPLE COMMENTS BY SENTIMENT:\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    for sentiment in ['bullish', 'bearish', 'neutral']:\n",
    "        sentiment_comments = comments_df[comments_df['Combined_Sentiment'] == sentiment]\n",
    "        if not sentiment_comments.empty:\n",
    "            print(f\"\\n{sentiment.upper()} Comments ({len(sentiment_comments)} total):\")\n",
    "            for idx, row in sentiment_comments.head(2).iterrows():\n",
    "                print(f\"  \\\"{row['Comment_Text'][:100]}...\\\"\")\n",
    "                print(f\"     {row['Comment_Date']} | Score: {row['Comment_Score']} | Hinglish: {row['Is_Hinglish']}\")\n",
    "    \n",
    "    # Show top Hinglish comments\n",
    "    hinglish_comments = comments_df[comments_df['Is_Hinglish'] == True]\n",
    "    if not hinglish_comments.empty:\n",
    "        print(f\"\\nTOP HINGLISH COMMENTS (Showing 3 examples):\")\n",
    "        print(\"-\" * 40)\n",
    "        top_hinglish = hinglish_comments.nlargest(3, 'Hinglish_Score')\n",
    "        for idx, row in top_hinglish.iterrows():\n",
    "            print(f\"\\\"{row['Comment_Text'][:80]}...\\\"\")\n",
    "            print(f\"   Sentiment: {row['Combined_Sentiment']} | Score: {row['Hinglish_Score']} | Date: {row['Comment_Date']}\")\n",
    "            print()\n",
    "    \n",
    "    # Display dataset info\n",
    "    print(f\"COMMENTS DATASET PREVIEW:\")\n",
    "    print(\"=\" * 60)\n",
    "    display_cols = ['Comment_Text', 'Combined_Sentiment', 'Is_Hinglish', 'Hinglish_Score', 'Comment_Date']\n",
    "    preview_df = comments_df[display_cols].head(3).copy()\n",
    "    # Truncate comment text for display\n",
    "    preview_df['Comment_Text'] = preview_df['Comment_Text'].str[:50] + '...'\n",
    "    print(preview_df.to_string(index=False))\n",
    "    \n",
    "    # Export comments to CSV\n",
    "    print(f\"\\n💾 EXPORTING COMMENTS DATA:\")\n",
    "    print(\"=\" * 30)\n",
    "    \n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    base_ticker = selectedTickerSymbol.replace('.NS', '')\n",
    "    comments_filename = f\"{base_ticker}_individual_comments_{timestamp}.csv\"\n",
    "    \n",
    "    # Export all comments\n",
    "    comments_df.to_csv(comments_filename, index=False)\n",
    "    print(f\"Comments data saved: {comments_filename}\")\n",
    "    print(f\"   Total comments: {len(comments_df)}\")\n",
    "    print(f\"   Columns: {len(comments_df.columns)}\")\n",
    "    \n",
    "    # Export only Hinglish comments if available\n",
    "    if not hinglish_comments.empty:\n",
    "        hinglish_filename = f\"{base_ticker}_hinglish_comments_only_{timestamp}.csv\"\n",
    "        hinglish_comments.to_csv(hinglish_filename, index=False)\n",
    "        print(f\"Hinglish-only data saved: {hinglish_filename}\")\n",
    "        print(f\"   Hinglish comments: {len(hinglish_comments)}\")\n",
    "    \n",
    "    print(f\"\\n🎯 FINAL COMMENTS SUMMARY:\")\n",
    "    print(f\"   📝 Individual comments extracted: {len(comments_df)}\")\n",
    "    print(f\"   🇮🇳 Pure Hinglish comments: {len(hinglish_comments)}\")\n",
    "    print(f\"   📅 Date range: {comments_df['Comment_Date'].min()} to {comments_df['Comment_Date'].max()}\")\n",
    "    \n",
    "    # Sentiment distribution\n",
    "    sentiment_dist = comments_df['Combined_Sentiment'].value_counts()\n",
    "    print(f\"   📊 Sentiment distribution:\")\n",
    "    for sentiment, count in sentiment_dist.items():\n",
    "        print(f\"      {sentiment.title()}: {count} ({count/len(comments_df)*100:.1f}%)\")\n",
    "\n",
    "else:\n",
    "    print(\"No comments found! Try:\")\n",
    "    print(\"   - Reducing hinglish_only to False\")\n",
    "    print(\"   - Increasing howmanysubmissions\")  \n",
    "    print(\"   - Changing time_period to 'year' or 'all'\")\n",
    "    print(\"   - Reducing min_hinglish_score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2fbd115a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Starting enhanced analysis of r/indianstocks for RELIANCE.NS\n",
      "🇮🇳 Focusing on Hinglish content with sentiment labeling\n",
      "============================================================\n",
      " Processing 100 submissions for Hinglish content...\n",
      " This may take several minutes...\n",
      "\n",
      "Post 1: This is what real ball looks like.....\n",
      "Post 1: This is what real ball looks like.....\n",
      "   💬 Processed 63 comments\n",
      "   ✅ 5 mentions, sentiment: bullish (Hinglish score: 5)\n",
      "\n",
      "Post 2: Telegram Trader's...\n",
      "   💬 Processed 63 comments\n",
      "   ✅ 5 mentions, sentiment: bullish (Hinglish score: 5)\n",
      "\n",
      "Post 2: Telegram Trader's...\n",
      "   💬 Processed 16 comments\n",
      "   ⏭️ Only 0 mentions - Skipped\n",
      "\n",
      "Post 3: Never forget...\n",
      "   💬 Processed 16 comments\n",
      "   ⏭️ Only 0 mentions - Skipped\n",
      "\n",
      "Post 3: Never forget...\n",
      "   💬 Processed 4 comments\n",
      "   ⏭️ Only 0 mentions - Skipped\n",
      "\n",
      "Post 4: I didn’t touch my stocks for 4 years and this is the result…...\n",
      "   💬 Processed 4 comments\n",
      "   ⏭️ Only 0 mentions - Skipped\n",
      "\n",
      "Post 4: I didn’t touch my stocks for 4 years and this is the result…...\n",
      "   💬 Processed 45 comments\n",
      "   ⏭️ Only 0 mentions - Skipped\n",
      "\n",
      "Post 5: OMG Now What 😱...\n",
      "   💬 Processed 45 comments\n",
      "   ⏭️ Only 0 mentions - Skipped\n",
      "\n",
      "Post 5: OMG Now What 😱...\n",
      "   💬 Processed 20 comments\n",
      "   ✅ 2 mentions, sentiment: neutral (Hinglish score: 14)\n",
      "\n",
      "Post 6: Indians are getting out of poverty 🇮🇳👍...\n",
      "   💬 Processed 20 comments\n",
      "   ✅ 2 mentions, sentiment: neutral (Hinglish score: 14)\n",
      "\n",
      "Post 6: Indians are getting out of poverty 🇮🇳👍...\n",
      "   💬 Processed 13 comments\n",
      "   ⏭️ Only 0 mentions - Skipped\n",
      "\n",
      "Post 7: Indian market these days....\n",
      "   💬 Processed 13 comments\n",
      "   ⏭️ Only 0 mentions - Skipped\n",
      "\n",
      "Post 7: Indian market these days....\n",
      "   💬 Processed 10 comments\n",
      "   ⏭️ Only 0 mentions - Skipped\n",
      "\n",
      "Post 8: How do tariffs work?...\n",
      "   💬 Processed 10 comments\n",
      "   ⏭️ Only 0 mentions - Skipped\n",
      "\n",
      "Post 8: How do tariffs work?...\n",
      "   💬 Processed 10 comments\n",
      "   ✅ 1 mentions, sentiment: neutral (Hinglish score: 10)\n",
      "\n",
      "Post 9: Rate My Portfolio 😁😁...\n",
      "   💬 Processed 10 comments\n",
      "   ✅ 1 mentions, sentiment: neutral (Hinglish score: 10)\n",
      "\n",
      "Post 9: Rate My Portfolio 😁😁...\n",
      "   💬 Processed 99 comments\n",
      "   ✅ 2 mentions, sentiment: bullish (Hinglish score: 17)\n",
      "\n",
      "Post 10: Made my first ₹100 profit!...\n",
      "   💬 Processed 99 comments\n",
      "   ✅ 2 mentions, sentiment: bullish (Hinglish score: 17)\n",
      "\n",
      "Post 10: Made my first ₹100 profit!...\n",
      "   💬 Processed 82 comments\n",
      "   ⏭️ Only 0 mentions - Skipped\n",
      "\n",
      "Post 11: Holding since IPO...\n",
      "   💬 Processed 82 comments\n",
      "   ⏭️ Only 0 mentions - Skipped\n",
      "\n",
      "Post 11: Holding since IPO...\n",
      "   💬 Processed 26 comments\n",
      "   ✅ 1 mentions, sentiment: bullish (Hinglish score: 10)\n",
      "\n",
      "Post 12: All these companies rake in 40-80% of their revenue from the...\n",
      "   💬 Processed 26 comments\n",
      "   ✅ 1 mentions, sentiment: bullish (Hinglish score: 10)\n",
      "\n",
      "Post 12: All these companies rake in 40-80% of their revenue from the...\n",
      "   💬 Processed 17 comments\n",
      "   ⏭️ Only 0 mentions - Skipped\n",
      "\n",
      "Post 13: Capital Gains Tax: India vs few other countries...\n",
      "   💬 Processed 17 comments\n",
      "   ⏭️ Only 0 mentions - Skipped\n",
      "\n",
      "Post 13: Capital Gains Tax: India vs few other countries...\n",
      "   💬 Processed 55 comments\n",
      "   ⏭️ Only 0 mentions - Skipped\n",
      "\n",
      "Post 14: Should I sell??...\n",
      "   💬 Processed 55 comments\n",
      "   ⏭️ Only 0 mentions - Skipped\n",
      "\n",
      "Post 14: Should I sell??...\n",
      "   💬 Processed 98 comments\n",
      "   ⏭️ Only 0 mentions - Skipped\n",
      "\n",
      "Post 15: Made some investments in 2016-2018 period and did not touch ...\n",
      "   💬 Processed 98 comments\n",
      "   ⏭️ Only 0 mentions - Skipped\n",
      "\n",
      "Post 15: Made some investments in 2016-2018 period and did not touch ...\n",
      "   💬 Processed 12 comments\n",
      "   ✅ 1 mentions, sentiment: bullish (Hinglish score: 11)\n",
      "\n",
      "Post 16: Indian Companies Exposure to USA & their Sales contribution...\n",
      "   💬 Processed 12 comments\n",
      "   ✅ 1 mentions, sentiment: bullish (Hinglish score: 11)\n",
      "\n",
      "Post 16: Indian Companies Exposure to USA & their Sales contribution...\n",
      "   ⏭️ Only 0 mentions - Skipped\n",
      "\n",
      "Post 17: NETWEB made me 150% in 4 months....\n",
      "   ⏭️ Only 0 mentions - Skipped\n",
      "\n",
      "Post 17: NETWEB made me 150% in 4 months....\n",
      "   💬 Processed 30 comments\n",
      "   ⏭️ Only 0 mentions - Skipped\n",
      "\n",
      "Post 18: Thanks to random anonymous reddit user...\n",
      "   💬 Processed 30 comments\n",
      "   ⏭️ Only 0 mentions - Skipped\n",
      "\n",
      "Post 18: Thanks to random anonymous reddit user...\n",
      "   💬 Processed 24 comments\n",
      "   ⏭️ Only 0 mentions - Skipped\n",
      "\n",
      "Post 19: Crossed 1 Crore today...\n",
      "   💬 Processed 24 comments\n",
      "   ⏭️ Only 0 mentions - Skipped\n",
      "\n",
      "Post 19: Crossed 1 Crore today...\n",
      "   💬 Processed 45 comments\n",
      "   ⏭️ Only 0 mentions - Skipped\n",
      "\n",
      "Post 20: How it will going to impact oil stocks?...\n",
      "   💬 Processed 45 comments\n",
      "   ⏭️ Only 0 mentions - Skipped\n",
      "\n",
      "Post 20: How it will going to impact oil stocks?...\n",
      "   💬 Processed 75 comments\n",
      "   ✅ 14 mentions, sentiment: bullish (Hinglish score: 3)\n",
      "\n",
      "Post 21: Do you think the market will fall because of the recent \"for...\n",
      "   💬 Processed 75 comments\n",
      "   ✅ 14 mentions, sentiment: bullish (Hinglish score: 3)\n",
      "\n",
      "Post 21: Do you think the market will fall because of the recent \"for...\n",
      "   💬 Processed 32 comments\n",
      "   ✅ 4 mentions, sentiment: bullish (Hinglish score: 15)\n",
      "\n",
      "Post 22: Sell time? Big win...\n",
      "   💬 Processed 32 comments\n",
      "   ✅ 4 mentions, sentiment: bullish (Hinglish score: 15)\n",
      "\n",
      "Post 22: Sell time? Big win...\n",
      "   💬 Processed 28 comments\n",
      "   ⏭️ Only 0 mentions - Skipped\n",
      "\n",
      "Post 23: At the end of the year, I got a 46% return this year. How mu...\n",
      "   💬 Processed 28 comments\n",
      "   ⏭️ Only 0 mentions - Skipped\n",
      "\n",
      "Post 23: At the end of the year, I got a 46% return this year. How mu...\n",
      "   💬 Processed 95 comments\n",
      "   ✅ 7 mentions, sentiment: bullish (Hinglish score: 7)\n",
      "\n",
      "Post 24: India Tops Hong Kong as World’s Fourth-Largest Stock Market...\n",
      "   💬 Processed 95 comments\n",
      "   ✅ 7 mentions, sentiment: bullish (Hinglish score: 7)\n",
      "\n",
      "Post 24: India Tops Hong Kong as World’s Fourth-Largest Stock Market...\n",
      "   💬 Processed 8 comments\n",
      "   ✅ 4 mentions, sentiment: neutral (Hinglish score: 8)\n",
      "\n",
      "Post 25: You can get Generational Wealth in Market...Just Don't Quit ...\n",
      "   💬 Processed 8 comments\n",
      "   ✅ 4 mentions, sentiment: neutral (Hinglish score: 8)\n",
      "\n",
      "Post 25: You can get Generational Wealth in Market...Just Don't Quit ...\n",
      "   💬 Processed 11 comments\n",
      "   ⏭️ Only 0 mentions - Skipped\n",
      "\n",
      "Post 26: Found Something Unexpected While Cleaning for Diwali...\n",
      "   💬 Processed 11 comments\n",
      "   ⏭️ Only 0 mentions - Skipped\n",
      "\n",
      "Post 26: Found Something Unexpected While Cleaning for Diwali...\n",
      "   💬 Processed 35 comments\n",
      "   ✅ 2 mentions, sentiment: bullish (Hinglish score: 14)\n",
      "\n",
      "Post 27: Zerodha's market share is shrinking?...\n",
      "   💬 Processed 35 comments\n",
      "   ✅ 2 mentions, sentiment: bullish (Hinglish score: 14)\n",
      "\n",
      "Post 27: Zerodha's market share is shrinking?...\n",
      "   💬 Processed 29 comments\n",
      "   ⏭️ Only 0 mentions - Skipped\n",
      "\n",
      "Post 28: I regret not buying more ITC at those levels ☹️...\n",
      "   💬 Processed 29 comments\n",
      "   ⏭️ Only 0 mentions - Skipped\n",
      "\n",
      "Post 28: I regret not buying more ITC at those levels ☹️...\n",
      "   💬 Processed 38 comments\n",
      "   ✅ 1 mentions, sentiment: bullish (Hinglish score: 13)\n",
      "\n",
      "Post 29: Zerodha CEO gives a detailed reply to a Reddit question on p...\n",
      "   💬 Processed 38 comments\n",
      "   ✅ 1 mentions, sentiment: bullish (Hinglish score: 13)\n",
      "\n",
      "Post 29: Zerodha CEO gives a detailed reply to a Reddit question on p...\n",
      "   💬 Processed 12 comments\n",
      "   ✅ 1 mentions, sentiment: bullish (Hinglish score: 6)\n",
      "\n",
      "Post 30: Trump after tariff...\n",
      "   💬 Processed 12 comments\n",
      "   ✅ 1 mentions, sentiment: bullish (Hinglish score: 6)\n",
      "\n",
      "Post 30: Trump after tariff...\n",
      "   ⏭️ Only 0 mentions - Skipped\n",
      "\n",
      "Post 31: At 23 made first lakh with investing any suggestions?...\n",
      "   ⏭️ Only 0 mentions - Skipped\n",
      "\n",
      "Post 31: At 23 made first lakh with investing any suggestions?...\n",
      "   💬 Processed 46 comments\n",
      "   ⏭️ Only 0 mentions - Skipped\n",
      "\n",
      "Post 32: My Portfolio hit 50K...\n",
      "   💬 Processed 46 comments\n",
      "   ⏭️ Only 0 mentions - Skipped\n",
      "\n",
      "Post 32: My Portfolio hit 50K...\n",
      "   💬 Processed 38 comments\n",
      "   ⏭️ Only 0 mentions - Skipped\n",
      "\n",
      "Post 33: China's Embassy in the US posted this on Donald Trump's tarr...\n",
      "   💬 Processed 38 comments\n",
      "   ⏭️ Only 0 mentions - Skipped\n",
      "\n",
      "Post 33: China's Embassy in the US posted this on Donald Trump's tarr...\n",
      "   💬 Processed 10 comments\n",
      "   ⏭️ Only 0 mentions - Skipped\n",
      "\n",
      "Post 34: My First ever trade...\n",
      "   💬 Processed 10 comments\n",
      "   ⏭️ Only 0 mentions - Skipped\n",
      "\n",
      "Post 34: My First ever trade...\n",
      "   💬 Processed 29 comments\n",
      "   ⏭️ Only 0 mentions - Skipped\n",
      "\n",
      "Post 35: This is how a 4 year old portfolio should look like. XIRR is...\n",
      "   💬 Processed 29 comments\n",
      "   ⏭️ Only 0 mentions - Skipped\n",
      "\n",
      "Post 35: This is how a 4 year old portfolio should look like. XIRR is...\n",
      "   💬 Processed 34 comments\n",
      "   ⏭️ Only 0 mentions - Skipped\n",
      "\n",
      "Post 36: what happened?...\n",
      "   💬 Processed 34 comments\n",
      "   ⏭️ Only 0 mentions - Skipped\n",
      "\n",
      "Post 36: what happened?...\n",
      "   💬 Processed 39 comments\n",
      "   ⏭️ Only 0 mentions - Skipped\n",
      "\n",
      "Post 37: How fucked am i...\n",
      "   💬 Processed 39 comments\n",
      "   ⏭️ Only 0 mentions - Skipped\n",
      "\n",
      "Post 37: How fucked am i...\n",
      "   💬 Processed 98 comments\n",
      "   ✅ 2 mentions, sentiment: bullish (Hinglish score: 6)\n",
      "\n",
      "Post 38: Why this meme is soo close to my reality...\n",
      "   💬 Processed 98 comments\n",
      "   ✅ 2 mentions, sentiment: bullish (Hinglish score: 6)\n",
      "\n",
      "Post 38: Why this meme is soo close to my reality...\n",
      "   💬 Processed 3 comments\n",
      "   ⏭️ Only 0 mentions - Skipped\n",
      "\n",
      "Post 39: Rate my investment.......\n",
      "   💬 Processed 3 comments\n",
      "   ⏭️ Only 0 mentions - Skipped\n",
      "\n",
      "Post 39: Rate my investment.......\n",
      "   💬 Processed 30 comments\n",
      "   ⏭️ Only 0 mentions - Skipped\n",
      "\n",
      "Post 40: Guys,tell me a right price to buy this...\n",
      "   💬 Processed 30 comments\n",
      "   ⏭️ Only 0 mentions - Skipped\n",
      "\n",
      "Post 40: Guys,tell me a right price to buy this...\n",
      "   💬 Processed 53 comments\n",
      "   ⏭️ Only 0 mentions - Skipped\n",
      "\n",
      "Post 41: I lost everything.......\n",
      "   💬 Processed 53 comments\n",
      "   ⏭️ Only 0 mentions - Skipped\n",
      "\n",
      "Post 41: I lost everything.......\n",
      "   💬 Processed 100 comments\n",
      "   ✅ 1 mentions, sentiment: bullish (Hinglish score: 6)\n",
      "\n",
      "Post 42: Patience is the key...\n",
      "   💬 Processed 100 comments\n",
      "   ✅ 1 mentions, sentiment: bullish (Hinglish score: 6)\n",
      "\n",
      "Post 42: Patience is the key...\n",
      "   💬 Processed 18 comments\n",
      "   ✅ 2 mentions, sentiment: bullish (Hinglish score: 13)\n",
      "\n",
      "Post 43: Why are gold prices rising?...\n",
      "   💬 Processed 18 comments\n",
      "   ✅ 2 mentions, sentiment: bullish (Hinglish score: 13)\n",
      "\n",
      "Post 43: Why are gold prices rising?...\n",
      "   💬 Processed 13 comments\n",
      "   ⏭️ Only 0 mentions - Skipped\n",
      "\n",
      "Post 44: Looking to hold for next 3 years...\n",
      "   💬 Processed 13 comments\n",
      "   ⏭️ Only 0 mentions - Skipped\n",
      "\n",
      "Post 44: Looking to hold for next 3 years...\n",
      "   💬 Processed 22 comments\n",
      "   ⏭️ Only 0 mentions - Skipped\n",
      "\n",
      "Post 45: I am scared, What should I do?...\n",
      "   💬 Processed 22 comments\n",
      "   ⏭️ Only 0 mentions - Skipped\n",
      "\n",
      "Post 45: I am scared, What should I do?...\n",
      "   💬 Processed 100 comments\n",
      "   ✅ 12 mentions, sentiment: bullish (Hinglish score: 12)\n",
      "\n",
      "Post 46: No returns in 3 years 😌...\n",
      "   💬 Processed 100 comments\n",
      "   ✅ 12 mentions, sentiment: bullish (Hinglish score: 12)\n",
      "\n",
      "Post 46: No returns in 3 years 😌...\n",
      "   💬 Processed 22 comments\n",
      "   ⏭️ Only 0 mentions - Skipped\n",
      "\n",
      "Post 47: Regret not adding more!...\n",
      "   💬 Processed 22 comments\n",
      "   ⏭️ Only 0 mentions - Skipped\n",
      "\n",
      "Post 47: Regret not adding more!...\n",
      "   💬 Processed 14 comments\n",
      "   ✅ 2 mentions, sentiment: bullish (Hinglish score: 9)\n",
      "\n",
      "Post 48: Bought this today...thoughts?...\n",
      "   💬 Processed 14 comments\n",
      "   ✅ 2 mentions, sentiment: bullish (Hinglish score: 9)\n",
      "\n",
      "Post 48: Bought this today...thoughts?...\n",
      "   💬 Processed 74 comments\n",
      "   ✅ 3 mentions, sentiment: bullish (Hinglish score: 10)\n",
      "\n",
      "Post 49: NETWEB doubled in 9 weeks for me. What to do?...\n",
      "   💬 Processed 74 comments\n",
      "   ✅ 3 mentions, sentiment: bullish (Hinglish score: 10)\n",
      "\n",
      "Post 49: NETWEB doubled in 9 weeks for me. What to do?...\n",
      "   💬 Processed 37 comments\n",
      "   ⏭️ Only 0 mentions - Skipped\n",
      "\n",
      "Post 50: As a 27yo, am I investing correctly?...\n",
      "   💬 Processed 37 comments\n",
      "   ⏭️ Only 0 mentions - Skipped\n",
      "\n",
      "Post 50: As a 27yo, am I investing correctly?...\n",
      "   💬 Processed 41 comments\n",
      "   ⏭️ Only 0 mentions - Skipped\n",
      "\n",
      "Post 51: Gold my beloved. It's given me better returns in 4 months th...\n",
      "   💬 Processed 41 comments\n",
      "   ⏭️ Only 0 mentions - Skipped\n",
      "\n",
      "Post 51: Gold my beloved. It's given me better returns in 4 months th...\n",
      "   💬 Processed 32 comments\n",
      "   ⏭️ Only 0 mentions - Skipped\n",
      "\n",
      "Post 52: Nifty call or put?...\n",
      "   💬 Processed 32 comments\n",
      "   ⏭️ Only 0 mentions - Skipped\n",
      "\n",
      "Post 52: Nifty call or put?...\n",
      "   💬 Processed 14 comments\n",
      "   ✅ 3 mentions, sentiment: bullish (Hinglish score: 24)\n",
      "\n",
      "Post 53: My first trade...\n",
      "   💬 Processed 14 comments\n",
      "   ✅ 3 mentions, sentiment: bullish (Hinglish score: 24)\n",
      "\n",
      "Post 53: My first trade...\n",
      "   💬 Processed 41 comments\n",
      "   ⏭️ Only 0 mentions - Skipped\n",
      "\n",
      "Post 54: Here's my portfolio: Investing for the long term. Your view ...\n",
      "   💬 Processed 41 comments\n",
      "   ⏭️ Only 0 mentions - Skipped\n",
      "\n",
      "Post 54: Here's my portfolio: Investing for the long term. Your view ...\n",
      "   💬 Processed 70 comments\n",
      "   ✅ 1 mentions, sentiment: bullish (Hinglish score: 12)\n",
      "\n",
      "Post 55: What's your opinion...\n",
      "   💬 Processed 70 comments\n",
      "   ✅ 1 mentions, sentiment: bullish (Hinglish score: 12)\n",
      "\n",
      "Post 55: What's your opinion...\n",
      "   💬 Processed 18 comments\n",
      "   ⏭️ Only 0 mentions - Skipped\n",
      "\n",
      "Post 56: What say guys? Double down?...\n",
      "   💬 Processed 18 comments\n",
      "   ⏭️ Only 0 mentions - Skipped\n",
      "\n",
      "Post 56: What say guys? Double down?...\n",
      "   💬 Processed 39 comments\n",
      "   ✅ 2 mentions, sentiment: bullish (Hinglish score: 3)\n",
      "\n",
      "Post 57: What does this mean...\n",
      "   💬 Processed 39 comments\n",
      "   ✅ 2 mentions, sentiment: bullish (Hinglish score: 3)\n",
      "\n",
      "Post 57: What does this mean...\n",
      "   💬 Processed 50 comments\n",
      "   ✅ 1 mentions, sentiment: neutral (Hinglish score: 4)\n",
      "\n",
      "Post 58: Please review my portfolio...\n",
      "   💬 Processed 50 comments\n",
      "   ✅ 1 mentions, sentiment: neutral (Hinglish score: 4)\n",
      "\n",
      "Post 58: Please review my portfolio...\n",
      "   💬 Processed 59 comments\n",
      "   ⏭️ Only 0 mentions - Skipped\n",
      "\n",
      "Post 59: Is this normal...\n",
      "   💬 Processed 59 comments\n",
      "   ⏭️ Only 0 mentions - Skipped\n",
      "\n",
      "Post 59: Is this normal...\n",
      "   💬 Processed 53 comments\n",
      "   ✅ 1 mentions, sentiment: bullish (Hinglish score: 5)\n",
      "\n",
      "Post 60: Rate My Portfolio and Advice ?...\n",
      "   💬 Processed 53 comments\n",
      "   ✅ 1 mentions, sentiment: bullish (Hinglish score: 5)\n",
      "\n",
      "Post 60: Rate My Portfolio and Advice ?...\n",
      "   💬 Processed 44 comments\n",
      "   ⏭️ Only 0 mentions - Skipped\n",
      "\n",
      "Post 61: Hyundai plans a $3 billion IPO for its India operation, valu...\n",
      "   💬 Processed 44 comments\n",
      "   ⏭️ Only 0 mentions - Skipped\n",
      "\n",
      "Post 61: Hyundai plans a $3 billion IPO for its India operation, valu...\n",
      "   ⏭️ Only 0 mentions - Skipped\n",
      "\n",
      "Post 62: Best decicion to not square off WAREEENER...thanks to Dad...\n",
      "   ⏭️ Only 0 mentions - Skipped\n",
      "\n",
      "Post 62: Best decicion to not square off WAREEENER...thanks to Dad...\n",
      "   💬 Processed 18 comments\n",
      "   ⏭️ Only 0 mentions - Skipped\n",
      "\n",
      "Post 63: Made 54% returns in 5 years of investing bit by bit. Anythin...\n",
      "   💬 Processed 18 comments\n",
      "   ⏭️ Only 0 mentions - Skipped\n",
      "\n",
      "Post 63: Made 54% returns in 5 years of investing bit by bit. Anythin...\n",
      "   💬 Processed 44 comments\n",
      "   ⏭️ Only 0 mentions - Skipped\n",
      "\n",
      "Post 64: Made good money....\n",
      "   💬 Processed 44 comments\n",
      "   ⏭️ Only 0 mentions - Skipped\n",
      "\n",
      "Post 64: Made good money....\n",
      "   💬 Processed 16 comments\n",
      "   ⏭️ Only 0 mentions - Skipped\n",
      "\n",
      "Post 65: Catch it Before it Explodes !!...\n",
      "   💬 Processed 16 comments\n",
      "   ⏭️ Only 0 mentions - Skipped\n",
      "\n",
      "Post 65: Catch it Before it Explodes !!...\n",
      "   💬 Processed 13 comments\n",
      "   ⏭️ Only 0 mentions - Skipped\n",
      "\n",
      "Post 66: After good response/comments for my ICICI demat account, ple...\n",
      "   💬 Processed 13 comments\n",
      "   ⏭️ Only 0 mentions - Skipped\n",
      "\n",
      "Post 66: After good response/comments for my ICICI demat account, ple...\n",
      "   💬 Processed 60 comments\n",
      "   ⏭️ Only 0 mentions - Skipped\n",
      "\n",
      "Post 67: Went all in on Gold & Silver...\n",
      "   💬 Processed 60 comments\n",
      "   ⏭️ Only 0 mentions - Skipped\n",
      "\n",
      "Post 67: Went all in on Gold & Silver...\n",
      "   💬 Processed 30 comments\n",
      "   ⏭️ Only 0 mentions - Skipped\n",
      "\n",
      "Post 68: Stay or Leave?...\n",
      "   💬 Processed 30 comments\n",
      "   ⏭️ Only 0 mentions - Skipped\n",
      "\n",
      "Post 68: Stay or Leave?...\n",
      "   💬 Processed 98 comments\n",
      "   ✅ 7 mentions, sentiment: bullish (Hinglish score: 14)\n",
      "\n",
      "Post 69: Trump has played the game well...\n",
      "   💬 Processed 98 comments\n",
      "   ✅ 7 mentions, sentiment: bullish (Hinglish score: 14)\n",
      "\n",
      "Post 69: Trump has played the game well...\n",
      "   💬 Processed 28 comments\n",
      "   ✅ 1 mentions, sentiment: neutral (Hinglish score: 3)\n",
      "\n",
      "Post 70: Some shares I am planning to buy tomorrow... Any suggestions...\n",
      "   💬 Processed 28 comments\n",
      "   ✅ 1 mentions, sentiment: neutral (Hinglish score: 3)\n",
      "\n",
      "Post 70: Some shares I am planning to buy tomorrow... Any suggestions...\n",
      "   💬 Processed 43 comments\n",
      "   ⏭️ Only 0 mentions - Skipped\n",
      "\n",
      "Post 71: Bye Bye FnO account...\n",
      "   💬 Processed 43 comments\n",
      "   ⏭️ Only 0 mentions - Skipped\n",
      "\n",
      "Post 71: Bye Bye FnO account...\n",
      "   💬 Processed 38 comments\n",
      "   ⏭️ Only 0 mentions - Skipped\n",
      "\n",
      "Post 72: Indians Pay More for Petrol Than Americans, Chinese & Pakist...\n",
      "   💬 Processed 38 comments\n",
      "   ⏭️ Only 0 mentions - Skipped\n",
      "\n",
      "Post 72: Indians Pay More for Petrol Than Americans, Chinese & Pakist...\n",
      "   💬 Processed 24 comments\n",
      "   ✅ 1 mentions, sentiment: neutral (Hinglish score: 3)\n",
      "\n",
      "Post 73: Good time to buy?...\n",
      "   💬 Processed 24 comments\n",
      "   ✅ 1 mentions, sentiment: neutral (Hinglish score: 3)\n",
      "\n",
      "Post 73: Good time to buy?...\n",
      "   💬 Processed 36 comments\n",
      "   ⏭️ Only 0 mentions - Skipped\n",
      "\n",
      "Post 74: Rate my portfolio out of 10...\n",
      "   💬 Processed 36 comments\n",
      "   ⏭️ Only 0 mentions - Skipped\n",
      "\n",
      "Post 74: Rate my portfolio out of 10...\n",
      "   💬 Processed 53 comments\n",
      "   ⏭️ Only 0 mentions - Skipped\n",
      "\n",
      "Post 75: Should I hold it or sell it?...\n",
      "   💬 Processed 53 comments\n",
      "   ⏭️ Only 0 mentions - Skipped\n",
      "\n",
      "Post 75: Should I hold it or sell it?...\n",
      "   💬 Processed 69 comments\n",
      "   ⏭️ Only 0 mentions - Skipped\n",
      "\n",
      "Post 76: India has been the worst performing market in the world over...\n",
      "   💬 Processed 69 comments\n",
      "   ⏭️ Only 0 mentions - Skipped\n",
      "\n",
      "Post 76: India has been the worst performing market in the world over...\n",
      "   💬 Processed 12 comments\n",
      "   ⏭️ Only 0 mentions - Skipped\n",
      "\n",
      "Post 77: Rate my portfolio...\n",
      "   💬 Processed 12 comments\n",
      "   ⏭️ Only 0 mentions - Skipped\n",
      "\n",
      "Post 77: Rate my portfolio...\n",
      "   💬 Processed 35 comments\n",
      "   ⏭️ Only 0 mentions - Skipped\n",
      "\n",
      "Post 78: My plan for 2 lakh investment...\n",
      "   💬 Processed 35 comments\n",
      "   ⏭️ Only 0 mentions - Skipped\n",
      "\n",
      "Post 78: My plan for 2 lakh investment...\n",
      "   💬 Processed 24 comments\n",
      "   ⏭️ Only 0 mentions - Skipped\n",
      "\n",
      "Post 79: What should I do with Tata Technologies ?...\n",
      "   💬 Processed 24 comments\n",
      "   ⏭️ Only 0 mentions - Skipped\n",
      "\n",
      "Post 79: What should I do with Tata Technologies ?...\n",
      "   💬 Processed 66 comments\n",
      "   ⏭️ Only 0 mentions - Skipped\n",
      "\n",
      "Post 80: Small Stock price Vs Small Company...\n",
      "   💬 Processed 66 comments\n",
      "   ⏭️ Only 0 mentions - Skipped\n",
      "\n",
      "Post 80: Small Stock price Vs Small Company...\n",
      "   💬 Processed 15 comments\n",
      "   ⏭️ Only 0 mentions - Skipped\n",
      "\n",
      "Post 81: US markets are crazyyy...\n",
      "   💬 Processed 15 comments\n",
      "   ⏭️ Only 0 mentions - Skipped\n",
      "\n",
      "Post 81: US markets are crazyyy...\n",
      "   💬 Processed 36 comments\n",
      "   ✅ 1 mentions, sentiment: bullish (Hinglish score: 21)\n",
      "\n",
      "Post 82: By mistake clicked 5 instead of 50...\n",
      "   💬 Processed 36 comments\n",
      "   ✅ 1 mentions, sentiment: bullish (Hinglish score: 21)\n",
      "\n",
      "Post 82: By mistake clicked 5 instead of 50...\n",
      "   💬 Processed 9 comments\n",
      "   ⏭️ Only 0 mentions - Skipped\n",
      "\n",
      "Post 83: Made ₹2460 profit this month from delivery stocks, paying ₹3...\n",
      "   💬 Processed 9 comments\n",
      "   ⏭️ Only 0 mentions - Skipped\n",
      "\n",
      "Post 83: Made ₹2460 profit this month from delivery stocks, paying ₹3...\n",
      "   💬 Processed 33 comments\n",
      "   ⏭️ Only 0 mentions - Skipped\n",
      "\n",
      "Post 84: Buy now or wait ? Tell me experts...\n",
      "   💬 Processed 33 comments\n",
      "   ⏭️ Only 0 mentions - Skipped\n",
      "\n",
      "Post 84: Buy now or wait ? Tell me experts...\n",
      "   💬 Processed 80 comments\n",
      "   ✅ 2 mentions, sentiment: bullish (Hinglish score: 18)\n",
      "\n",
      "Post 85: Wait for 1 Cr. Or Exit ?...\n",
      "   💬 Processed 80 comments\n",
      "   ✅ 2 mentions, sentiment: bullish (Hinglish score: 18)\n",
      "\n",
      "Post 85: Wait for 1 Cr. Or Exit ?...\n",
      "   💬 Processed 24 comments\n",
      "   ⏭️ Only 0 mentions - Skipped\n",
      "\n",
      "Post 86: Rate this portfolio...\n",
      "   💬 Processed 24 comments\n",
      "   ⏭️ Only 0 mentions - Skipped\n",
      "\n",
      "Post 86: Rate this portfolio...\n",
      "   💬 Processed 23 comments\n",
      "   ✅ 2 mentions, sentiment: bullish (Hinglish score: 12)\n",
      "\n",
      "Post 87: My portfolio at 22....\n",
      "   💬 Processed 23 comments\n",
      "   ✅ 2 mentions, sentiment: bullish (Hinglish score: 12)\n",
      "\n",
      "Post 87: My portfolio at 22....\n",
      "   💬 Processed 29 comments\n",
      "   ⏭️ Only 0 mentions - Skipped\n",
      "\n",
      "Post 88: Hyundai is here 🔥🔥...\n",
      "   💬 Processed 29 comments\n",
      "   ⏭️ Only 0 mentions - Skipped\n",
      "\n",
      "Post 88: Hyundai is here 🔥🔥...\n",
      "   💬 Processed 35 comments\n",
      "   ⏭️ Only 0 mentions - Skipped\n",
      "\n",
      "Post 89: TCS: A buying opportunity? Please suggest....\n",
      "   💬 Processed 35 comments\n",
      "   ⏭️ Only 0 mentions - Skipped\n",
      "\n",
      "Post 89: TCS: A buying opportunity? Please suggest....\n",
      "   💬 Processed 44 comments\n",
      "   ✅ 1 mentions, sentiment: bullish (Hinglish score: 12)\n",
      "\n",
      "Post 90: Found my dad’s stock portfolio — where do I start?...\n",
      "   💬 Processed 44 comments\n",
      "   ✅ 1 mentions, sentiment: bullish (Hinglish score: 12)\n",
      "\n",
      "Post 90: Found my dad’s stock portfolio — where do I start?...\n",
      "   💬 Processed 15 comments\n",
      "   ✅ 4 mentions, sentiment: bullish (Hinglish score: 10)\n",
      "\n",
      "Post 91: Help with your suggestion and rate my portfolio as newbie....\n",
      "   💬 Processed 15 comments\n",
      "   ✅ 4 mentions, sentiment: bullish (Hinglish score: 10)\n",
      "\n",
      "Post 91: Help with your suggestion and rate my portfolio as newbie....\n",
      "   💬 Processed 40 comments\n",
      "   ⏭️ Only 0 mentions - Skipped\n",
      "\n",
      "Post 92: What should I do and don't...\n",
      "   💬 Processed 40 comments\n",
      "   ⏭️ Only 0 mentions - Skipped\n",
      "\n",
      "Post 92: What should I do and don't...\n",
      "   💬 Processed 29 comments\n",
      "   ⏭️ Only 0 mentions - Skipped\n",
      "\n",
      "Post 93: Damn. Got a Valentine gift...\n",
      "   💬 Processed 29 comments\n",
      "   ⏭️ Only 0 mentions - Skipped\n",
      "\n",
      "Post 93: Damn. Got a Valentine gift...\n",
      "   💬 Processed 8 comments\n",
      "   ⏭️ Only 0 mentions - Skipped\n",
      "\n",
      "Post 94: Should I buy it? Is it right time...\n",
      "   💬 Processed 8 comments\n",
      "   ⏭️ Only 0 mentions - Skipped\n",
      "\n",
      "Post 94: Should I buy it? Is it right time...\n",
      "   💬 Processed 44 comments\n",
      "   ⏭️ Only 0 mentions - Skipped\n",
      "\n",
      "Post 95: Should I sell or hold?...\n",
      "   💬 Processed 44 comments\n",
      "   ⏭️ Only 0 mentions - Skipped\n",
      "\n",
      "Post 95: Should I sell or hold?...\n",
      "   💬 Processed 36 comments\n",
      "   ⏭️ Only 0 mentions - Skipped\n",
      "\n",
      "Post 96: Want to invest 3 lakhs in stocks. Need help!...\n",
      "   💬 Processed 36 comments\n",
      "   ⏭️ Only 0 mentions - Skipped\n",
      "\n",
      "Post 96: Want to invest 3 lakhs in stocks. Need help!...\n",
      "   💬 Processed 34 comments\n",
      "   ✅ 1 mentions, sentiment: bullish (Hinglish score: 10)\n",
      "\n",
      "Post 97: Did something positive happen?...\n",
      "   💬 Processed 34 comments\n",
      "   ✅ 1 mentions, sentiment: bullish (Hinglish score: 10)\n",
      "\n",
      "Post 97: Did something positive happen?...\n",
      "   💬 Processed 18 comments\n",
      "   ✅ 1 mentions, sentiment: bearish (Hinglish score: 6)\n",
      "\n",
      "Post 98: Months of research...\n",
      "   💬 Processed 18 comments\n",
      "   ✅ 1 mentions, sentiment: bearish (Hinglish score: 6)\n",
      "\n",
      "Post 98: Months of research...\n",
      "   💬 Processed 21 comments\n",
      "   ⏭️ Only 0 mentions - Skipped\n",
      "\n",
      "Post 99: 30 M , can you guys rate my portfolio and how much can i imp...\n",
      "   💬 Processed 21 comments\n",
      "   ⏭️ Only 0 mentions - Skipped\n",
      "\n",
      "Post 99: 30 M , can you guys rate my portfolio and how much can i imp...\n",
      "   💬 Processed 39 comments\n",
      "   ⏭️ Only 0 mentions - Skipped\n",
      "\n",
      "Post 100: NIFTY 🫣...\n",
      "   💬 Processed 39 comments\n",
      "   ⏭️ Only 0 mentions - Skipped\n",
      "\n",
      "Post 100: NIFTY 🫣...\n",
      "   ⏭️ Only 0 mentions - Skipped\n",
      "\n",
      " Enhanced analysis completed!\n",
      "============================================================\n",
      " ENHANCED ANALYSIS SUMMARY:\n",
      "    Total submissions processed: 100\n",
      "    Posts mentioning RELIANCE.NS: 34\n",
      "    Total ticker mentions: 96\n",
      "   🇮🇳 Hinglish posts found: 34\n",
      "    Final Hinglish dataset size: 34 records\n",
      "\n",
      "📊 SENTIMENT BREAKDOWN:\n",
      "    Bullish: 27 (79.4%)\n",
      "    Neutral: 6 (17.6%)\n",
      "    Bearish: 1 (2.9%)\n",
      "   ⏭️ Only 0 mentions - Skipped\n",
      "\n",
      " Enhanced analysis completed!\n",
      "============================================================\n",
      " ENHANCED ANALYSIS SUMMARY:\n",
      "    Total submissions processed: 100\n",
      "    Posts mentioning RELIANCE.NS: 34\n",
      "    Total ticker mentions: 96\n",
      "   🇮🇳 Hinglish posts found: 34\n",
      "    Final Hinglish dataset size: 34 records\n",
      "\n",
      "📊 SENTIMENT BREAKDOWN:\n",
      "    Bullish: 27 (79.4%)\n",
      "    Neutral: 6 (17.6%)\n",
      "    Bearish: 1 (2.9%)\n"
     ]
    }
   ],
   "source": [
    "# Main analysis - process Reddit submissions with enhanced Hinglish filtering\n",
    "print(f\"Starting enhanced analysis of r/{selectedsubreddit} for {selectedTickerSymbol}\")\n",
    "print(\"Focusing on Hinglish content with sentiment labeling\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Get Reddit submissions based on time period  \n",
    "try:\n",
    "    if time_period == 'week':\n",
    "        submissions = reddit.subreddit(selectedsubreddit).top('week', limit=howmanysubmissions)\n",
    "    elif time_period == 'month':\n",
    "        submissions = reddit.subreddit(selectedsubreddit).top('month', limit=howmanysubmissions)\n",
    "    elif time_period == 'year':\n",
    "        submissions = reddit.subreddit(selectedsubreddit).top('year', limit=howmanysubmissions)\n",
    "    else:\n",
    "        submissions = reddit.subreddit(selectedsubreddit).top('all', limit=howmanysubmissions)\n",
    "    \n",
    "    # Initialize results dataframe\n",
    "    results_df = pd.DataFrame()\n",
    "    \n",
    "    # Analysis counters\n",
    "    submission_counter = 1\n",
    "    total_posts_with_ticker = 0\n",
    "    total_ticker_mentions = 0\n",
    "    hinglish_posts = 0\n",
    "    \n",
    "    print(f\"Processing {howmanysubmissions} submissions for Hinglish content...\")\n",
    "    print(\" This may take several minutes...\\n\")\n",
    "    \n",
    "    # Process each submission\n",
    "    for submission in submissions:\n",
    "        try:\n",
    "            # Reset global counter for this submission\n",
    "            selectedTickerSymbolCount = 0\n",
    "            \n",
    "            # Initialize sentiment counters\n",
    "            sub_entries_textblob = {'negative': 0, 'positive': 0, 'neutral': 0}\n",
    "            sub_entries_nltk = {'negative': 0, 'positive': 0, 'neutral': 0}\n",
    "            \n",
    "            # Clean title and analyze\n",
    "            clean_title = clean_text(submission.title)\n",
    "            \n",
    "            print(f\"Post {submission_counter}: {clean_title[:60]}...\")\n",
    "            submission_counter += 1\n",
    "            \n",
    "            # Analyze title sentiment\n",
    "            text_blob_sentiment(clean_title, sub_entries_textblob)\n",
    "            nltk_sentiment(clean_title, sub_entries_nltk)\n",
    "            \n",
    "            # Count ticker mentions in title\n",
    "            count_ticker_mentions(clean_title, selectedTickerSymbol)\n",
    "            \n",
    "            # Check for Hinglish content in title\n",
    "            title_hinglish, title_hinglish_score = is_hinglish(clean_title)\n",
    "            \n",
    "            # Check comments for Hinglish and sentiment if enabled\n",
    "            comment_hinglish_scores = []\n",
    "            if analyze_comments:\n",
    "                try:\n",
    "                    submission.comments.replace_more(limit=0)\n",
    "                    processed_comments = 0\n",
    "                    \n",
    "                    # First pass: check for Hinglish in first 10 comments\n",
    "                    for comment in submission.comments[:10]:\n",
    "                        try:\n",
    "                            if hasattr(comment, 'body') and comment.body not in ['[deleted]', '[removed]']:\n",
    "                                _, comment_score = is_hinglish(comment.body)\n",
    "                                if comment_score > 0:\n",
    "                                    comment_hinglish_scores.append(comment_score)\n",
    "                        except:\n",
    "                            continue\n",
    "                    \n",
    "                    # Calculate total Hinglish score early\n",
    "                    total_hinglish_score = title_hinglish_score + sum(comment_hinglish_scores)\n",
    "                    is_hinglish_content = total_hinglish_score >= 2\n",
    "                    \n",
    "                    # Only process all comments if content has potential\n",
    "                    if selectedTickerSymbolCount >= min_ticker_mentions or is_hinglish_content:\n",
    "                        for comment in submission.comments[:max_comments_per_post]:\n",
    "                            try:\n",
    "                                if hasattr(comment, 'body') and comment.body not in ['[deleted]', '[removed]']:\n",
    "                                    clean_comment = clean_text(comment.body)\n",
    "                                    \n",
    "                                    # Analyze comment sentiment\n",
    "                                    text_blob_sentiment(clean_comment, sub_entries_textblob)\n",
    "                                    nltk_sentiment(clean_comment, sub_entries_nltk)\n",
    "                                    \n",
    "                                    # Count ticker mentions\n",
    "                                    count_ticker_mentions(clean_comment, selectedTickerSymbol)\n",
    "                                    \n",
    "                                    # Process replies\n",
    "                                    process_comment_replies(comment, sub_entries_textblob, sub_entries_nltk, selectedTickerSymbol)\n",
    "                                    \n",
    "                                    processed_comments += 1\n",
    "                            except:\n",
    "                                continue\n",
    "                        \n",
    "                        print(f\"   Processed {processed_comments} comments\")\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"   ⚠️ Error processing comments: {e}\")\n",
    "                    total_hinglish_score = title_hinglish_score\n",
    "            else:\n",
    "                total_hinglish_score = title_hinglish_score\n",
    "            \n",
    "            # Final Hinglish determination\n",
    "            is_hinglish_post = total_hinglish_score >= 2\n",
    "            \n",
    "            # Determine if we should record this post\n",
    "            should_process = selectedTickerSymbolCount >= min_ticker_mentions\n",
    "            if hinglish_only:\n",
    "                should_process = should_process and is_hinglish_post\n",
    "            \n",
    "            if should_process:\n",
    "                total_posts_with_ticker += 1\n",
    "                total_ticker_mentions += selectedTickerSymbolCount\n",
    "                \n",
    "                if is_hinglish_post:\n",
    "                    hinglish_posts += 1\n",
    "                \n",
    "                # Get post timestamp\n",
    "                post_date = datetime.fromtimestamp(submission.created_utc)\n",
    "                \n",
    "                # Determine overall sentiment labels\n",
    "                vader_sentiment = 'Neutral'\n",
    "                if sub_entries_nltk.get('positive', 0) > sub_entries_nltk.get('negative', 0):\n",
    "                    vader_sentiment = 'Positive'\n",
    "                elif sub_entries_nltk.get('negative', 0) > sub_entries_nltk.get('positive', 0):\n",
    "                    vader_sentiment = 'Negative'\n",
    "                \n",
    "                textblob_sentiment = 'Neutral'\n",
    "                if sub_entries_textblob.get('positive', 0) > sub_entries_textblob.get('negative', 0):\n",
    "                    textblob_sentiment = 'Positive'\n",
    "                elif sub_entries_textblob.get('negative', 0) > sub_entries_textblob.get('positive', 0):\n",
    "                    textblob_sentiment = 'Negative'\n",
    "                \n",
    "                # Get combined sentiment label\n",
    "                combined_sentiment = get_sentiment_label(textblob_sentiment, vader_sentiment)\n",
    "                \n",
    "                # Create record with enhanced features\n",
    "                record = {\n",
    "                    'Title': clean_title,\n",
    "                    'Ticker': selectedTickerSymbol,\n",
    "                    'Date': post_date.strftime('%Y-%m-%d'),\n",
    "                    'DateTime': post_date,\n",
    "                    'Post_ID': submission.id,\n",
    "                    'Score': submission.score,\n",
    "                    'Num_Comments': submission.num_comments,\n",
    "                    'Author': str(submission.author) if submission.author else '[deleted]',\n",
    "                    'NumberOfTickerMentions': selectedTickerSymbolCount,\n",
    "                    'Is_Hinglish': is_hinglish_post,\n",
    "                    'Hinglish_Score': total_hinglish_score,\n",
    "                    'VADER_Sentiment': vader_sentiment,\n",
    "                    'TextBlob_Sentiment': textblob_sentiment,\n",
    "                    'Combined_Sentiment': combined_sentiment,\n",
    "                    'VADER_Negative': sub_entries_nltk.get('negative', 0),\n",
    "                    'VADER_Positive': sub_entries_nltk.get('positive', 0),\n",
    "                    'VADER_Neutral': sub_entries_nltk.get('neutral', 0),\n",
    "                    'TextBlob_Negative': sub_entries_textblob.get('negative', 0),\n",
    "                    'TextBlob_Positive': sub_entries_textblob.get('positive', 0),\n",
    "                    'TextBlob_Neutral': sub_entries_textblob.get('neutral', 0)\n",
    "                }\n",
    "                \n",
    "                # Append to results\n",
    "                results_df = pd.concat([results_df, pd.DataFrame([record])], ignore_index=True)\n",
    "                \n",
    "                hinglish_status = f\"(Hinglish score: {total_hinglish_score})\" if is_hinglish_post else \"(Not Hinglish)\"\n",
    "                print(f\"   {selectedTickerSymbolCount} mentions, sentiment: {combined_sentiment} {hinglish_status}\")\n",
    "            else:\n",
    "                if selectedTickerSymbolCount < min_ticker_mentions:\n",
    "                    print(f\"   Only {selectedTickerSymbolCount} mentions - Skipped\")\n",
    "                elif hinglish_only and not is_hinglish_post:\n",
    "                    print(f\"   Not Hinglish content (score: {total_hinglish_score}) - Skipped\")\n",
    "                else:\n",
    "                    print(f\"   Skipped\")\n",
    "            \n",
    "            print()  # Empty line for readability\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"    Error processing submission: {e}\")\n",
    "            continue\n",
    "    \n",
    "    print(\"Enhanced analysis completed!\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"ENHANCED ANALYSIS SUMMARY:\")\n",
    "    print(f\"    Total submissions processed: {submission_counter - 1}\")\n",
    "    print(f\"    Posts mentioning {selectedTickerSymbol}: {total_posts_with_ticker}\")\n",
    "    print(f\"    Total ticker mentions: {total_ticker_mentions}\")\n",
    "    print(f\"   Hinglish posts found: {hinglish_posts}\")\n",
    "    print(f\"    Final Hinglish dataset size: {len(results_df)} records\")\n",
    "    \n",
    "    # Show sentiment breakdown if we have data\n",
    "    if not results_df.empty:\n",
    "        sentiment_counts = results_df['Combined_Sentiment'].value_counts()\n",
    "        print(f\"\\n📊 SENTIMENT BREAKDOWN:\")\n",
    "        for sentiment, count in sentiment_counts.items():\n",
    "            print(f\"    {sentiment.title()}: {count} ({count/len(results_df)*100:.1f}%)\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\" Error during analysis: {e}\")\n",
    "    results_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea9d2281",
   "metadata": {},
   "source": [
    "## 10. Generate Sentiment Analysis Results\n",
    "\n",
    "Display and analyze the sentiment analysis results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3510c102",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " DETAILED SENTIMENT ANALYSIS RESULTS\n",
      "============================================================\n",
      "🔍 VADER Sentiment Analysis:\n",
      "    Positive: 985 (35.5%)\n",
      "    Negative: 519 (18.7%)\n",
      "    Neutral: 1273 (45.8%)\n",
      "\n",
      "🔍 TextBlob Sentiment Analysis:\n",
      "    Positive: 776 (27.9%)\n",
      "    Negative: 274 (9.9%)\n",
      "    Neutral: 1727 (62.2%)\n",
      "\n",
      "============================================================\n",
      " OVERALL SENTIMENT SCORES:\n",
      "   VADER Score: +0.168 (-1 to +1)\n",
      "   TextBlob Score: +0.181 (-1 to +1)\n",
      "   🎯 Overall Sentiment: 🐂 BULLISH (+0.174)\n",
      "\n",
      "🔥 TOP POSTS BY RELIANCE.NS MENTIONS:\n",
      "------------------------------------------------------------\n",
      " How it will going to impact oil stocks?...\n",
      "    14 mentions | 📅 2025-06-15 | 👍 414 upvotes\n",
      "\n",
      " I am scared, What should I do?...\n",
      "    12 mentions | 📅 2025-02-18 | 👍 236 upvotes\n",
      "\n",
      " At the end of the year, I got a 46% return this year. How much return did you ge...\n",
      "    7 mentions | 📅 2023-12-30 | 👍 388 upvotes\n",
      "\n",
      " Stay or Leave?...\n",
      "    7 mentions | 📅 2025-02-06 | 👍 168 upvotes\n",
      "\n",
      " This is what real ball looks like.....\n",
      "    5 mentions | 📅 2025-03-05 | 👍 4415 upvotes\n",
      "\n",
      "🇮🇳 HINGLISH CONTENT ANALYSIS:\n",
      "    Hinglish posts: 34 out of 34 (100.0%)\n",
      "\n",
      " DATASET PREVIEW (First 3 rows):\n",
      "============================================================\n",
      "                              Title       Date  NumberOfTickerMentions  VADER_Positive  VADER_Negative  TextBlob_Positive  TextBlob_Negative\n",
      "This is what real ball looks like.. 2025-03-05                       5              52              40                 42                 17\n",
      "                     OMG Now What 😱 2025-08-06                       2               6               7                  5                  3\n",
      "               How do tariffs work? 2025-04-06                       1              11              15                 14                  2\n"
     ]
    }
   ],
   "source": [
    "# Analyze and display sentiment results\n",
    "if not results_df.empty:\n",
    "    print(\"DETAILED SENTIMENT ANALYSIS RESULTS\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Calculate sentiment totals\n",
    "    total_vader_pos = results_df['VADER_Positive'].sum()\n",
    "    total_vader_neg = results_df['VADER_Negative'].sum()\n",
    "    total_vader_neu = results_df['VADER_Neutral'].sum()\n",
    "    \n",
    "    total_textblob_pos = results_df['TextBlob_Positive'].sum()\n",
    "    total_textblob_neg = results_df['TextBlob_Negative'].sum()\n",
    "    total_textblob_neu = results_df['TextBlob_Neutral'].sum()\n",
    "    \n",
    "    # VADER Analysis\n",
    "    print(\"VADER Sentiment Analysis:\")\n",
    "    vader_total = total_vader_pos + total_vader_neg + total_vader_neu\n",
    "    if vader_total > 0:\n",
    "        print(f\"    Positive: {total_vader_pos} ({total_vader_pos/vader_total*100:.1f}%)\")\n",
    "        print(f\"    Negative: {total_vader_neg} ({total_vader_neg/vader_total*100:.1f}%)\")\n",
    "        print(f\"    Neutral: {total_vader_neu} ({total_vader_neu/vader_total*100:.1f}%)\")\n",
    "    \n",
    "    print()\n",
    "    \n",
    "    # TextBlob Analysis\n",
    "    print(\"TextBlob Sentiment Analysis:\")\n",
    "    textblob_total = total_textblob_pos + total_textblob_neg + total_textblob_neu\n",
    "    if textblob_total > 0:\n",
    "        print(f\"    Positive: {total_textblob_pos} ({total_textblob_pos/textblob_total*100:.1f}%)\")\n",
    "        print(f\"    Negative: {total_textblob_neg} ({total_textblob_neg/textblob_total*100:.1f}%)\")\n",
    "        print(f\"    Neutral: {total_textblob_neu} ({total_textblob_neu/textblob_total*100:.1f}%)\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    \n",
    "    # Overall sentiment score calculation\n",
    "    vader_sentiment_score = (total_vader_pos - total_vader_neg) / max(vader_total, 1)\n",
    "    textblob_sentiment_score = (total_textblob_pos - total_textblob_neg) / max(textblob_total, 1)\n",
    "    \n",
    "    print(f\"OVERALL SENTIMENT SCORES:\")\n",
    "    print(f\"   VADER Score: {vader_sentiment_score:+.3f} (-1 to +1)\")\n",
    "    print(f\"   TextBlob Score: {textblob_sentiment_score:+.3f} (-1 to +1)\")\n",
    "    \n",
    "    # Determine overall sentiment\n",
    "    avg_sentiment = (vader_sentiment_score + textblob_sentiment_score) / 2\n",
    "    if avg_sentiment > 0.1:\n",
    "        overall_sentiment = \"BULLISH\"\n",
    "    elif avg_sentiment < -0.1:\n",
    "        overall_sentiment = \"BEARISH\"\n",
    "    else:\n",
    "        overall_sentiment = \"NEUTRAL\"\n",
    "    \n",
    "    print(f\"   Overall Sentiment: {overall_sentiment} ({avg_sentiment:+.3f})\")\n",
    "    \n",
    "    # Show top posts by ticker mentions\n",
    "    print(f\"\\nTOP POSTS BY {selectedTickerSymbol} MENTIONS:\")\n",
    "    print(\"-\" * 60)\n",
    "    top_posts = results_df.nlargest(5, 'NumberOfTickerMentions')\n",
    "    for idx, row in top_posts.iterrows():\n",
    "        print(f\" {row['Title'][:80]}...\")\n",
    "        print(f\"    {row['NumberOfTickerMentions']} mentions | {row['Date']} | {row['Score']} upvotes\")\n",
    "        print()\n",
    "    \n",
    "    # Hinglish analysis\n",
    "    hinglish_count = results_df['Is_Hinglish'].sum()\n",
    "    print(f\"HINGLISH CONTENT ANALYSIS:\")\n",
    "    print(f\"    Hinglish posts: {hinglish_count} out of {len(results_df)} ({hinglish_count/len(results_df)*100:.1f}%)\")\n",
    "    \n",
    "    # Display first few rows of the dataset\n",
    "    print(f\"\\nDATASET PREVIEW (First 3 rows):\")\n",
    "    print(\"=\" * 60)\n",
    "    display_columns = ['Title', 'Date', 'NumberOfTickerMentions', 'VADER_Positive', 'VADER_Negative', 'TextBlob_Positive', 'TextBlob_Negative']\n",
    "    print(results_df[display_columns].head(3).to_string(index=False))\n",
    "    \n",
    "else:\n",
    "    print(\"No data found! Try:\")\n",
    "    print(\"   - Reducing min_ticker_mentions\")\n",
    "    print(\"   - Increasing howmanysubmissions\")\n",
    "    print(\"   - Changing time_period to 'year' or 'all'\")\n",
    "    print(\"   - Checking if ticker symbol is correct\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acf0c17d",
   "metadata": {},
   "source": [
    "## 11. Export Data to CSV Files\n",
    "\n",
    "Save the sentiment analysis results and stock data to CSV files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4be22a0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "💾 EXPORTING DATA TO CSV FILES\n",
      "========================================\n",
      "✅ Sentiment data saved: RELIANCE_comment_analysis_20251005_184106.csv\n",
      "   📊 Records: 34\n",
      "   📋 Columns: ['Title', 'Ticker', 'Date', 'DateTime', 'Post_ID', 'Score', 'Num_Comments', 'Author', 'NumberOfTickerMentions', 'Is_Hinglish', 'Hinglish_Score', 'VADER_Sentiment', 'TextBlob_Sentiment', 'Combined_Sentiment', 'VADER_Negative', 'VADER_Positive', 'VADER_Neutral', 'TextBlob_Negative', 'TextBlob_Positive', 'TextBlob_Neutral']\n",
      "✅ Stock data saved: RELIANCE_stock_history_20251005_184106.csv\n",
      "   📈 Price records: 252\n",
      "   📅 Date range: 2024-10-03 to 2025-10-03\n",
      "\n",
      "🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉\n",
      "🎉 ANALYSIS COMPLETE! 🎉\n",
      "🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉\n",
      "\n",
      "📊 FINAL SUMMARY FOR RELIANCE.NS:\n",
      "   🎯 Posts analyzed: 34\n",
      "   💬 Total ticker mentions: 96\n",
      "   📅 Date range: 2023-12-30 to 2025-10-03\n",
      "   🇮🇳 Hinglish content: 34 posts\n",
      "   📈 Overall sentiment: 🐂 BULLISH\n",
      "\n",
      "📁 FILES CREATED:\n",
      "   📊 RELIANCE_comment_analysis_20251005_184106.csv - Sentiment analysis results\n",
      "   📈 RELIANCE_stock_history_20251005_184106.csv - Stock price history\n",
      "\n",
      "🚀 Next Steps:\n",
      "   📈 Load the CSV files for further analysis\n",
      "   📊 Create visualizations to correlate sentiment with stock price\n",
      "   🤖 Train machine learning models for prediction\n",
      "   📝 Analyze Hinglish sentiment patterns\n",
      "\n",
      "✨ Analysis completed successfully! ✨\n"
     ]
    }
   ],
   "source": [
    "# Export results to CSV files\n",
    "print(\"EXPORTING DATA TO CSV FILES\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# Generate timestamp for unique filenames\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "base_ticker = selectedTickerSymbol.replace('.NS', '')\n",
    "\n",
    "try:\n",
    "    # Export sentiment analysis results\n",
    "    if not results_df.empty:\n",
    "        sentiment_filename = f\"{base_ticker}_comment_analysis_{timestamp}.csv\"\n",
    "        results_df.to_csv(sentiment_filename, index=False)\n",
    "        print(f\"Sentiment data saved: {sentiment_filename}\")\n",
    "        print(f\"   Records: {len(results_df)}\")\n",
    "        print(f\"   Columns: {list(results_df.columns)}\")\n",
    "    else:\n",
    "        print(\"No sentiment data to export\")\n",
    "    \n",
    "    # Export stock price data\n",
    "    if not stock_history.empty:\n",
    "        stock_filename = f\"{base_ticker}_stock_history_{timestamp}.csv\"\n",
    "        stock_history.to_csv(stock_filename, index=True)\n",
    "        print(f\"Stock data saved: {stock_filename}\")\n",
    "        print(f\"   Price records: {len(stock_history)}\")\n",
    "        print(f\"   Date range: {stock_history.index[0].date()} to {stock_history.index[-1].date()}\")\n",
    "    else:\n",
    "        print(\"No stock data to export\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 20)\n",
    "    print(\"ANALYSIS COMPLETE!\")\n",
    "    print(\"=\" * 20)\n",
    "    \n",
    "    if not results_df.empty:\n",
    "        print(f\"\\nFINAL SUMMARY FOR {selectedTickerSymbol}:\")\n",
    "        print(f\"   Posts analyzed: {len(results_df)}\")\n",
    "        print(f\"   Total ticker mentions: {results_df['NumberOfTickerMentions'].sum()}\")\n",
    "        print(f\"   Date range: {results_df['Date'].min()} to {results_df['Date'].max()}\")\n",
    "        print(f\"   Hinglish content: {results_df['Is_Hinglish'].sum()} posts\")\n",
    "        print(f\"   Overall sentiment: {overall_sentiment}\")\n",
    "        \n",
    "        print(f\"\\nFILES CREATED:\")\n",
    "        print(f\"   {sentiment_filename} - Sentiment analysis results\")\n",
    "        if not stock_history.empty:\n",
    "            print(f\"   {stock_filename} - Stock price history\")\n",
    "            \n",
    "        print(f\"\\nNext Steps:\")\n",
    "        print(f\"   Load the CSV files for further analysis\")\n",
    "        print(f\"   Create visualizations to correlate sentiment with stock price\")\n",
    "        print(f\"   Train machine learning models for prediction\")\n",
    "        print(f\"   Analyze Hinglish sentiment patterns\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"❌ Error during export: {e}\")\n",
    "\n",
    "print(f\"\\nAnalysis completed successfully!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
